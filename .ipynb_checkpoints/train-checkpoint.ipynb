{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ssd\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "res_net50 (ResNet50)         multiple                  14785408  \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           multiple                  262400    \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           multiple                  1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           multiple                  65664     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           multiple                  295168    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           multiple                  32896     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           multiple                  295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           multiple                  460900    \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           multiple                  1382550   \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           multiple                  691350    \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           multiple                  345750    \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           multiple                  230500    \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           multiple                  230500    \n",
      "=================================================================\n",
      "Total params: 20,258,926\n",
      "Trainable params: 20,213,998\n",
      "Non-trainable params: 44,928\n",
      "_________________________________________________________________\n",
      "Epoch: 0/50, step: 0/2141.0, 10.36s/step, loss: 118753.77344, cls loss: 237507.12500, reg loss: 0.42438\n",
      "Epoch: 0/50, step: 1/2141.0, 10.61s/step, loss: 86115.28125, cls loss: 172230.20312, reg loss: 0.36011\n",
      "Epoch: 0/50, step: 2/2141.0, 10.34s/step, loss: 70979.31250, cls loss: 141958.37500, reg loss: 0.24007\n",
      "Epoch: 0/50, step: 3/2141.0, 10.45s/step, loss: 61397.17969, cls loss: 122793.10938, reg loss: 1.24638\n",
      "Epoch: 0/50, step: 4/2141.0, 10.36s/step, loss: 54315.19531, cls loss: 108629.32812, reg loss: 1.06934\n",
      "Epoch: 0/50, step: 5/2141.0, 10.48s/step, loss: 48713.23047, cls loss: 97422.02344, reg loss: 4.44127\n",
      "Epoch: 0/50, step: 6/2141.0, 10.81s/step, loss: 44073.37500, cls loss: 88140.07812, reg loss: 6.67266\n",
      "Epoch: 0/50, step: 7/2141.0, 10.78s/step, loss: 40157.06641, cls loss: 80286.74219, reg loss: 27.39493\n",
      "Epoch: 0/50, step: 8/2141.0, 10.91s/step, loss: 36838.33594, cls loss: 73602.90625, reg loss: 73.76196\n",
      "Epoch: 0/50, step: 9/2141.0, 11.01s/step, loss: 33911.36328, cls loss: 67756.33594, reg loss: 66.38577\n",
      "Epoch: 0/50, step: 10/2141.0, 11.12s/step, loss: 31403.03125, cls loss: 62710.66406, reg loss: 95.39513\n",
      "Epoch: 0/50, step: 11/2141.0, 11.15s/step, loss: 29162.63281, cls loss: 58229.75000, reg loss: 95.51392\n",
      "Epoch: 0/50, step: 12/2141.0, 11.11s/step, loss: 27195.39453, cls loss: 54296.18359, reg loss: 94.60404\n",
      "Epoch: 0/50, step: 13/2141.0, 11.11s/step, loss: 25461.21484, cls loss: 50818.77734, reg loss: 103.64917\n",
      "Epoch: 0/50, step: 14/2141.0, 11.21s/step, loss: 23904.48633, cls loss: 47711.48828, reg loss: 97.48281\n",
      "Epoch: 0/50, step: 15/2141.0, 11.22s/step, loss: 22528.88672, cls loss: 44965.16016, reg loss: 92.60962\n",
      "Epoch: 0/50, step: 16/2141.0, 11.18s/step, loss: 21301.63867, cls loss: 42504.73438, reg loss: 98.53520\n",
      "Epoch: 0/50, step: 17/2141.0, 11.12s/step, loss: 20189.95508, cls loss: 40285.86328, reg loss: 94.04153\n",
      "Epoch: 0/50, step: 18/2141.0, 11.05s/step, loss: 19182.26953, cls loss: 38273.30078, reg loss: 91.23534\n",
      "Epoch: 0/50, step: 19/2141.0, 11.05s/step, loss: 18268.96680, cls loss: 36451.25000, reg loss: 86.67974\n",
      "Epoch: 0/50, step: 20/2141.0, 11.06s/step, loss: 17436.57031, cls loss: 34790.57812, reg loss: 82.55782\n",
      "Epoch: 0/50, step: 21/2141.0, 11.02s/step, loss: 16678.71484, cls loss: 33276.88672, reg loss: 80.53836\n",
      "Epoch: 0/50, step: 22/2141.0, 11.00s/step, loss: 15980.43164, cls loss: 31883.80664, reg loss: 77.05419\n",
      "Epoch: 0/50, step: 23/2141.0, 11.10s/step, loss: 15336.62402, cls loss: 30599.25977, reg loss: 73.98623\n",
      "Epoch: 0/50, step: 24/2141.0, 11.15s/step, loss: 14742.77246, cls loss: 29414.50977, reg loss: 71.03284\n",
      "Epoch: 0/50, step: 25/2141.0, 11.17s/step, loss: 14193.43262, cls loss: 28317.43555, reg loss: 69.42841\n",
      "Epoch: 0/50, step: 26/2141.0, 11.15s/step, loss: 13683.76367, cls loss: 27300.16602, reg loss: 67.35974\n",
      "Epoch: 0/50, step: 27/2141.0, 11.11s/step, loss: 13208.57910, cls loss: 26351.42578, reg loss: 65.72989\n",
      "Epoch: 0/50, step: 28/2141.0, 11.12s/step, loss: 12764.95020, cls loss: 25466.35156, reg loss: 63.54697\n",
      "Epoch: 0/50, step: 29/2141.0, 11.12s/step, loss: 12350.18164, cls loss: 24638.92383, reg loss: 61.43690\n",
      "Epoch: 0/50, step: 30/2141.0, 11.11s/step, loss: 11961.08398, cls loss: 23862.56250, reg loss: 59.60214\n",
      "Epoch: 0/50, step: 31/2141.0, 11.09s/step, loss: 11595.98633, cls loss: 23134.06055, reg loss: 57.90921\n",
      "Epoch: 0/50, step: 32/2141.0, 11.07s/step, loss: 11252.11719, cls loss: 22447.97266, reg loss: 56.25796\n",
      "Epoch: 0/50, step: 33/2141.0, 11.05s/step, loss: 10928.15332, cls loss: 21801.69141, reg loss: 54.61357\n",
      "Epoch: 0/50, step: 34/2141.0, 11.05s/step, loss: 10622.32227, cls loss: 21191.58984, reg loss: 53.05319\n",
      "Epoch: 0/50, step: 35/2141.0, 11.04s/step, loss: 10333.25879, cls loss: 20614.92773, reg loss: 51.58770\n",
      "Epoch: 0/50, step: 36/2141.0, 11.06s/step, loss: 10059.58691, cls loss: 20068.97070, reg loss: 50.19989\n",
      "Epoch: 0/50, step: 37/2141.0, 11.07s/step, loss: 9800.41699, cls loss: 19551.48828, reg loss: 49.34269\n",
      "Epoch: 0/50, step: 38/2141.0, 11.08s/step, loss: 9553.97949, cls loss: 19059.75586, reg loss: 48.19841\n",
      "Epoch: 0/50, step: 39/2141.0, 11.09s/step, loss: 9319.91992, cls loss: 18592.83594, reg loss: 47.00233\n",
      "Epoch: 0/50, step: 40/2141.0, 11.07s/step, loss: 9097.22461, cls loss: 18148.09375, reg loss: 46.35484\n",
      "Epoch: 0/50, step: 41/2141.0, 11.10s/step, loss: 8885.62305, cls loss: 17724.86523, reg loss: 46.38041\n",
      "Epoch: 0/50, step: 42/2141.0, 11.09s/step, loss: 8682.64062, cls loss: 17319.88477, reg loss: 45.39329\n",
      "Epoch: 0/50, step: 43/2141.0, 11.09s/step, loss: 8489.35645, cls loss: 16934.20898, reg loss: 44.50280\n",
      "Epoch: 0/50, step: 44/2141.0, 11.14s/step, loss: 8304.11719, cls loss: 16564.69922, reg loss: 43.53406\n",
      "Epoch: 0/50, step: 45/2141.0, 11.14s/step, loss: 8126.80566, cls loss: 16211.02148, reg loss: 42.58767\n",
      "Epoch: 0/50, step: 46/2141.0, 11.15s/step, loss: 7957.08984, cls loss: 15872.30078, reg loss: 41.87733\n",
      "Epoch: 0/50, step: 47/2141.0, 11.13s/step, loss: 7794.30322, cls loss: 15547.59277, reg loss: 41.01243\n",
      "Epoch: 0/50, step: 48/2141.0, 11.16s/step, loss: 7639.30859, cls loss: 15238.23730, reg loss: 40.37882\n",
      "Epoch: 0/50, step: 49/2141.0, 11.15s/step, loss: 7489.53174, cls loss: 14939.48730, reg loss: 39.57459\n",
      "Epoch: 0/50, step: 50/2141.0, 11.14s/step, loss: 7345.22852, cls loss: 14651.65723, reg loss: 38.79906\n",
      "Epoch: 0/50, step: 51/2141.0, 11.12s/step, loss: 7206.32520, cls loss: 14374.59570, reg loss: 38.05322\n",
      "Epoch: 0/50, step: 52/2141.0, 11.09s/step, loss: 7072.66943, cls loss: 14107.86523, reg loss: 37.47217\n",
      "Epoch: 0/50, step: 53/2141.0, 11.10s/step, loss: 6944.26562, cls loss: 13851.59863, reg loss: 36.93250\n",
      "Epoch: 0/50, step: 54/2141.0, 11.09s/step, loss: 6820.61670, cls loss: 13604.94727, reg loss: 36.28462\n",
      "Epoch: 0/50, step: 55/2141.0, 11.07s/step, loss: 6701.37061, cls loss: 13366.76660, reg loss: 35.97387\n",
      "Epoch: 0/50, step: 56/2141.0, 11.07s/step, loss: 6586.13574, cls loss: 13136.84863, reg loss: 35.42225\n",
      "Epoch: 0/50, step: 57/2141.0, 11.07s/step, loss: 6476.01074, cls loss: 12916.93945, reg loss: 35.08049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 58/2141.0, 11.07s/step, loss: 6368.51660, cls loss: 12702.53906, reg loss: 34.49294\n",
      "Epoch: 0/50, step: 59/2141.0, 11.10s/step, loss: 6264.72314, cls loss: 12495.52637, reg loss: 33.91893\n",
      "Epoch: 0/50, step: 60/2141.0, 11.08s/step, loss: 6163.92969, cls loss: 12294.49414, reg loss: 33.36445\n",
      "Epoch: 0/50, step: 61/2141.0, 11.08s/step, loss: 6066.17236, cls loss: 12099.51074, reg loss: 32.83238\n",
      "Epoch: 0/50, step: 62/2141.0, 11.08s/step, loss: 5971.63135, cls loss: 11910.93652, reg loss: 32.32457\n",
      "Epoch: 0/50, step: 63/2141.0, 11.09s/step, loss: 5880.04980, cls loss: 11728.13574, reg loss: 31.96134\n",
      "Epoch: 0/50, step: 64/2141.0, 11.07s/step, loss: 5791.37451, cls loss: 11551.25195, reg loss: 31.49504\n",
      "Epoch: 0/50, step: 65/2141.0, 11.05s/step, loss: 5705.02441, cls loss: 11379.02832, reg loss: 31.01881\n",
      "Epoch: 0/50, step: 66/2141.0, 11.04s/step, loss: 5621.45166, cls loss: 11212.34375, reg loss: 30.55717\n",
      "Epoch: 0/50, step: 67/2141.0, 11.03s/step, loss: 5540.35303, cls loss: 11050.57129, reg loss: 30.13204\n",
      "Epoch: 0/50, step: 68/2141.0, 11.03s/step, loss: 5461.66016, cls loss: 10893.59180, reg loss: 29.72712\n",
      "Epoch: 0/50, step: 69/2141.0, 11.02s/step, loss: 5385.09717, cls loss: 10740.88965, reg loss: 29.30317\n",
      "Epoch: 0/50, step: 70/2141.0, 11.02s/step, loss: 5310.75293, cls loss: 10592.59961, reg loss: 28.90501\n",
      "Epoch: 0/50, step: 71/2141.0, 11.02s/step, loss: 5238.52148, cls loss: 10448.49609, reg loss: 28.54432\n",
      "Epoch: 0/50, step: 72/2141.0, 11.06s/step, loss: 5168.02881, cls loss: 10307.90137, reg loss: 28.15377\n",
      "Epoch: 0/50, step: 73/2141.0, 11.04s/step, loss: 5099.46777, cls loss: 10171.14648, reg loss: 27.78650\n",
      "Epoch: 0/50, step: 74/2141.0, 11.03s/step, loss: 5032.83545, cls loss: 10038.24609, reg loss: 27.42222\n",
      "Epoch: 0/50, step: 75/2141.0, 11.04s/step, loss: 4968.00098, cls loss: 9908.92969, reg loss: 27.06962\n",
      "Epoch: 0/50, step: 76/2141.0, 11.03s/step, loss: 4904.60449, cls loss: 9782.48535, reg loss: 26.72093\n",
      "Epoch: 0/50, step: 77/2141.0, 11.02s/step, loss: 4842.90332, cls loss: 9659.42383, reg loss: 26.37946\n",
      "Epoch: 0/50, step: 78/2141.0, 11.03s/step, loss: 4782.88428, cls loss: 9539.70605, reg loss: 26.05980\n",
      "Epoch: 0/50, step: 79/2141.0, 11.01s/step, loss: 4724.21338, cls loss: 9422.68848, reg loss: 25.73478\n",
      "Epoch: 0/50, step: 80/2141.0, 11.00s/step, loss: 4666.97314, cls loss: 9308.52539, reg loss: 25.41763\n",
      "Epoch: 0/50, step: 81/2141.0, 10.99s/step, loss: 4611.18848, cls loss: 9197.25879, reg loss: 25.11599\n",
      "Epoch: 0/50, step: 82/2141.0, 10.98s/step, loss: 4556.69971, cls loss: 9088.58203, reg loss: 24.81440\n",
      "Epoch: 0/50, step: 83/2141.0, 10.99s/step, loss: 4503.69678, cls loss: 8982.77441, reg loss: 24.61538\n",
      "Epoch: 0/50, step: 84/2141.0, 10.99s/step, loss: 4451.72119, cls loss: 8879.11133, reg loss: 24.32759\n",
      "Epoch: 0/50, step: 85/2141.0, 11.01s/step, loss: 4401.08984, cls loss: 8778.12695, reg loss: 24.04811\n",
      "Epoch: 0/50, step: 86/2141.0, 11.01s/step, loss: 4351.56885, cls loss: 8679.35645, reg loss: 23.77736\n",
      "Epoch: 0/50, step: 87/2141.0, 11.01s/step, loss: 4303.09326, cls loss: 8582.66895, reg loss: 23.51326\n",
      "Epoch: 0/50, step: 88/2141.0, 11.01s/step, loss: 4255.77930, cls loss: 8488.13184, reg loss: 23.42303\n",
      "Epoch: 0/50, step: 89/2141.0, 11.00s/step, loss: 4209.60889, cls loss: 8396.04785, reg loss: 23.16651\n",
      "Epoch: 0/50, step: 90/2141.0, 11.02s/step, loss: 4164.31543, cls loss: 8305.70703, reg loss: 22.92104\n",
      "Epoch: 0/50, step: 91/2141.0, 11.01s/step, loss: 4119.95703, cls loss: 8217.23828, reg loss: 22.67248\n",
      "Epoch: 0/50, step: 92/2141.0, 11.00s/step, loss: 4076.80640, cls loss: 8131.15234, reg loss: 22.45757\n",
      "Epoch: 0/50, step: 93/2141.0, 10.99s/step, loss: 4034.30908, cls loss: 8046.39551, reg loss: 22.22005\n",
      "Epoch: 0/50, step: 94/2141.0, 10.98s/step, loss: 3992.78906, cls loss: 7963.58887, reg loss: 21.98695\n",
      "Epoch: 0/50, step: 95/2141.0, 10.97s/step, loss: 3952.10083, cls loss: 7882.41016, reg loss: 21.78959\n",
      "Epoch: 0/50, step: 96/2141.0, 10.98s/step, loss: 3912.26001, cls loss: 7802.94971, reg loss: 21.56760\n",
      "Epoch: 0/50, step: 97/2141.0, 10.99s/step, loss: 3873.15112, cls loss: 7724.94727, reg loss: 21.35204\n",
      "Epoch: 0/50, step: 98/2141.0, 10.97s/step, loss: 3834.83423, cls loss: 7648.52441, reg loss: 21.14056\n",
      "Epoch: 0/50, step: 99/2141.0, 10.96s/step, loss: 3797.23291, cls loss: 7573.52881, reg loss: 20.93373\n",
      "Epoch: 0/50, step: 100/2141.0, 10.96s/step, loss: 3760.51367, cls loss: 7500.29688, reg loss: 20.72719\n",
      "Epoch: 0/50, step: 101/2141.0, 10.95s/step, loss: 3724.45996, cls loss: 7428.37012, reg loss: 20.54619\n",
      "Epoch: 0/50, step: 102/2141.0, 10.94s/step, loss: 3689.22974, cls loss: 7357.97266, reg loss: 20.48309\n",
      "Epoch: 0/50, step: 103/2141.0, 10.94s/step, loss: 3654.50342, cls loss: 7288.71143, reg loss: 20.29191\n",
      "Epoch: 0/50, step: 104/2141.0, 10.93s/step, loss: 3620.40405, cls loss: 7220.70557, reg loss: 20.10020\n",
      "Epoch: 0/50, step: 105/2141.0, 10.92s/step, loss: 3586.95142, cls loss: 7153.98877, reg loss: 19.91085\n",
      "Epoch: 0/50, step: 106/2141.0, 10.93s/step, loss: 3554.20923, cls loss: 7088.67334, reg loss: 19.74169\n",
      "Epoch: 0/50, step: 107/2141.0, 10.92s/step, loss: 3522.00488, cls loss: 7024.44727, reg loss: 19.55958\n",
      "Epoch: 0/50, step: 108/2141.0, 10.92s/step, loss: 3490.86304, cls loss: 6961.53174, reg loss: 20.19125\n",
      "Epoch: 0/50, step: 109/2141.0, 10.92s/step, loss: 3459.76758, cls loss: 6899.52393, reg loss: 20.00846\n",
      "Epoch: 0/50, step: 110/2141.0, 10.92s/step, loss: 3429.19824, cls loss: 6838.56299, reg loss: 19.83047\n",
      "Epoch: 0/50, step: 111/2141.0, 10.94s/step, loss: 3399.24951, cls loss: 6778.83154, reg loss: 19.66428\n",
      "Epoch: 0/50, step: 112/2141.0, 10.94s/step, loss: 3369.82764, cls loss: 6720.16016, reg loss: 19.49155\n",
      "Epoch: 0/50, step: 113/2141.0, 10.94s/step, loss: 3341.05396, cls loss: 6662.72363, reg loss: 19.38136\n",
      "Epoch: 0/50, step: 114/2141.0, 10.94s/step, loss: 3312.63525, cls loss: 6606.05273, reg loss: 19.21467\n",
      "Epoch: 0/50, step: 115/2141.0, 10.93s/step, loss: 3284.69971, cls loss: 6550.34277, reg loss: 19.05313\n",
      "Epoch: 0/50, step: 116/2141.0, 10.92s/step, loss: 3257.20630, cls loss: 6495.51758, reg loss: 18.89127\n",
      "Epoch: 0/50, step: 117/2141.0, 10.92s/step, loss: 3230.22266, cls loss: 6441.69775, reg loss: 18.74439\n",
      "Epoch: 0/50, step: 118/2141.0, 10.94s/step, loss: 3203.71045, cls loss: 6388.82568, reg loss: 18.59154\n",
      "Epoch: 0/50, step: 119/2141.0, 10.93s/step, loss: 3177.58032, cls loss: 6336.71582, reg loss: 18.44125\n",
      "Epoch: 0/50, step: 120/2141.0, 10.93s/step, loss: 3151.89331, cls loss: 6285.47852, reg loss: 18.30464\n",
      "Epoch: 0/50, step: 121/2141.0, 10.93s/step, loss: 3126.65063, cls loss: 6235.14258, reg loss: 18.15519\n",
      "Epoch: 0/50, step: 122/2141.0, 10.93s/step, loss: 3101.75122, cls loss: 6185.49072, reg loss: 18.00823\n",
      "Epoch: 0/50, step: 123/2141.0, 10.93s/step, loss: 3077.26807, cls loss: 6136.66846, reg loss: 17.86437\n",
      "Epoch: 0/50, step: 124/2141.0, 10.93s/step, loss: 3053.21533, cls loss: 6088.69922, reg loss: 17.72789\n",
      "Epoch: 0/50, step: 125/2141.0, 10.93s/step, loss: 3029.54614, cls loss: 6041.49707, reg loss: 17.59164\n",
      "Epoch: 0/50, step: 126/2141.0, 10.92s/step, loss: 3006.18335, cls loss: 5994.90918, reg loss: 17.45430\n",
      "Epoch: 0/50, step: 127/2141.0, 10.91s/step, loss: 2983.19751, cls loss: 5949.07275, reg loss: 17.31875\n",
      "Epoch: 0/50, step: 128/2141.0, 10.91s/step, loss: 2960.54785, cls loss: 5903.90771, reg loss: 17.18468\n",
      "Epoch: 0/50, step: 129/2141.0, 10.91s/step, loss: 2938.22266, cls loss: 5859.38965, reg loss: 17.05273\n",
      "Epoch: 0/50, step: 130/2141.0, 10.91s/step, loss: 2916.25610, cls loss: 5815.58643, reg loss: 16.92282\n",
      "Epoch: 0/50, step: 131/2141.0, 10.91s/step, loss: 2894.64648, cls loss: 5772.49365, reg loss: 16.79617\n",
      "Epoch: 0/50, step: 132/2141.0, 10.91s/step, loss: 2873.36475, cls loss: 5730.05615, reg loss: 16.67043\n",
      "Epoch: 0/50, step: 133/2141.0, 10.90s/step, loss: 2852.41162, cls loss: 5688.25928, reg loss: 16.56065\n",
      "Epoch: 0/50, step: 134/2141.0, 10.90s/step, loss: 2831.74658, cls loss: 5647.05029, reg loss: 16.43958\n",
      "Epoch: 0/50, step: 135/2141.0, 10.91s/step, loss: 2811.40625, cls loss: 5606.48682, reg loss: 16.32309\n",
      "Epoch: 0/50, step: 136/2141.0, 10.91s/step, loss: 2791.38940, cls loss: 5566.55273, reg loss: 16.22339\n",
      "Epoch: 0/50, step: 137/2141.0, 10.91s/step, loss: 2771.58716, cls loss: 5527.06543, reg loss: 16.10623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 138/2141.0, 10.92s/step, loss: 2752.23145, cls loss: 5488.25781, reg loss: 16.20268\n",
      "Epoch: 0/50, step: 139/2141.0, 10.92s/step, loss: 2732.95825, cls loss: 5449.82568, reg loss: 16.08794\n",
      "Epoch: 0/50, step: 140/2141.0, 10.91s/step, loss: 2714.01636, cls loss: 5412.05469, reg loss: 15.97570\n",
      "Epoch: 0/50, step: 141/2141.0, 10.91s/step, loss: 2695.33374, cls loss: 5374.79248, reg loss: 15.87246\n",
      "Epoch: 0/50, step: 142/2141.0, 10.91s/step, loss: 2676.89062, cls loss: 5338.01611, reg loss: 15.76231\n",
      "Epoch: 0/50, step: 143/2141.0, 10.92s/step, loss: 2659.33398, cls loss: 5301.89551, reg loss: 16.77002\n",
      "Epoch: 0/50, step: 144/2141.0, 10.93s/step, loss: 2641.39062, cls loss: 5266.11279, reg loss: 16.66551\n",
      "Epoch: 0/50, step: 145/2141.0, 10.92s/step, loss: 2624.18945, cls loss: 5230.97119, reg loss: 17.40527\n",
      "Epoch: 0/50, step: 146/2141.0, 10.94s/step, loss: 2606.74536, cls loss: 5196.19189, reg loss: 17.29646\n",
      "Epoch: 0/50, step: 147/2141.0, 10.94s/step, loss: 2589.49658, cls loss: 5161.80469, reg loss: 17.18573\n",
      "Epoch: 0/50, step: 148/2141.0, 10.96s/step, loss: 2572.87476, cls loss: 5128.13379, reg loss: 17.61292\n",
      "Epoch: 0/50, step: 149/2141.0, 10.98s/step, loss: 2556.11646, cls loss: 5094.73193, reg loss: 17.49788\n",
      "Epoch: 0/50, step: 150/2141.0, 10.98s/step, loss: 2539.53125, cls loss: 5061.67676, reg loss: 17.38287\n",
      "Epoch: 0/50, step: 151/2141.0, 10.98s/step, loss: 2523.17603, cls loss: 5029.08008, reg loss: 17.26907\n",
      "Epoch: 0/50, step: 152/2141.0, 10.99s/step, loss: 2507.08081, cls loss: 4997.00098, reg loss: 17.15809\n",
      "Epoch: 0/50, step: 153/2141.0, 10.99s/step, loss: 2491.18335, cls loss: 4965.31250, reg loss: 17.05112\n",
      "Epoch: 0/50, step: 154/2141.0, 11.00s/step, loss: 2475.55664, cls loss: 4934.16846, reg loss: 16.94199\n",
      "Epoch: 0/50, step: 155/2141.0, 11.01s/step, loss: 2460.03101, cls loss: 4903.22412, reg loss: 16.83542\n",
      "Epoch: 0/50, step: 156/2141.0, 11.01s/step, loss: 2444.71460, cls loss: 4872.69727, reg loss: 16.72916\n",
      "Epoch: 0/50, step: 157/2141.0, 11.01s/step, loss: 2429.59644, cls loss: 4842.56543, reg loss: 16.62490\n",
      "Epoch: 0/50, step: 158/2141.0, 11.01s/step, loss: 2414.64771, cls loss: 4812.77051, reg loss: 16.52252\n",
      "Epoch: 0/50, step: 159/2141.0, 11.04s/step, loss: 2399.95459, cls loss: 4783.46582, reg loss: 16.44032\n",
      "Epoch: 0/50, step: 160/2141.0, 11.05s/step, loss: 2385.37866, cls loss: 4754.41504, reg loss: 16.33974\n",
      "Epoch: 0/50, step: 161/2141.0, 11.05s/step, loss: 2370.98047, cls loss: 4725.71875, reg loss: 16.23958\n",
      "Epoch: 0/50, step: 162/2141.0, 11.06s/step, loss: 2356.79102, cls loss: 4697.39844, reg loss: 16.18110\n",
      "Epoch: 0/50, step: 163/2141.0, 11.06s/step, loss: 2342.73218, cls loss: 4669.37842, reg loss: 16.08331\n",
      "Epoch: 0/50, step: 164/2141.0, 11.06s/step, loss: 2328.84155, cls loss: 4641.68457, reg loss: 15.99627\n",
      "Epoch: 0/50, step: 165/2141.0, 11.06s/step, loss: 2315.09229, cls loss: 4614.28076, reg loss: 15.90102\n",
      "Epoch: 0/50, step: 166/2141.0, 11.07s/step, loss: 2301.53809, cls loss: 4587.26807, reg loss: 15.80589\n",
      "Epoch: 0/50, step: 167/2141.0, 11.07s/step, loss: 2288.15674, cls loss: 4560.59814, reg loss: 15.71262\n",
      "Epoch: 0/50, step: 168/2141.0, 11.07s/step, loss: 2274.96313, cls loss: 4534.30273, reg loss: 15.62106\n",
      "Epoch: 0/50, step: 169/2141.0, 11.06s/step, loss: 2261.88281, cls loss: 4508.23193, reg loss: 15.53091\n",
      "Epoch: 0/50, step: 170/2141.0, 11.07s/step, loss: 2248.95020, cls loss: 4482.45703, reg loss: 15.44090\n",
      "Epoch: 0/50, step: 171/2141.0, 11.06s/step, loss: 2236.18896, cls loss: 4457.01123, reg loss: 15.36435\n",
      "Epoch: 0/50, step: 172/2141.0, 11.06s/step, loss: 2223.55591, cls loss: 4431.83301, reg loss: 15.27623\n",
      "Epoch: 0/50, step: 173/2141.0, 11.05s/step, loss: 2211.05566, cls loss: 4406.92041, reg loss: 15.18893\n",
      "Epoch: 0/50, step: 174/2141.0, 11.06s/step, loss: 2198.69580, cls loss: 4382.28711, reg loss: 15.10269\n",
      "Epoch: 0/50, step: 175/2141.0, 11.06s/step, loss: 2186.44556, cls loss: 4357.87158, reg loss: 15.01700\n",
      "Epoch: 0/50, step: 176/2141.0, 11.06s/step, loss: 2174.37061, cls loss: 4333.80615, reg loss: 14.93273\n",
      "Epoch: 0/50, step: 177/2141.0, 11.06s/step, loss: 2162.45508, cls loss: 4310.05664, reg loss: 14.85088\n",
      "Epoch: 0/50, step: 178/2141.0, 11.06s/step, loss: 2150.63745, cls loss: 4286.50439, reg loss: 14.76843\n",
      "Epoch: 0/50, step: 179/2141.0, 11.06s/step, loss: 2139.01147, cls loss: 4263.30322, reg loss: 14.71737\n",
      "Epoch: 0/50, step: 180/2141.0, 11.06s/step, loss: 2127.48975, cls loss: 4240.33154, reg loss: 14.64589\n",
      "Epoch: 0/50, step: 181/2141.0, 11.05s/step, loss: 2116.09644, cls loss: 4217.57861, reg loss: 14.61177\n",
      "Epoch: 0/50, step: 182/2141.0, 11.05s/step, loss: 2104.77588, cls loss: 4195.01758, reg loss: 14.53226\n",
      "Epoch: 0/50, step: 183/2141.0, 11.06s/step, loss: 2093.60059, cls loss: 4172.74512, reg loss: 14.45358\n",
      "Epoch: 0/50, step: 184/2141.0, 11.06s/step, loss: 2082.53271, cls loss: 4150.68701, reg loss: 14.37619\n",
      "Epoch: 0/50, step: 185/2141.0, 11.06s/step, loss: 2071.58374, cls loss: 4128.86523, reg loss: 14.29991\n",
      "Epoch: 0/50, step: 186/2141.0, 11.06s/step, loss: 2060.73926, cls loss: 4107.25146, reg loss: 14.22474\n",
      "Epoch: 0/50, step: 187/2141.0, 11.06s/step, loss: 2050.02002, cls loss: 4085.88672, reg loss: 14.15106\n",
      "Epoch: 0/50, step: 188/2141.0, 11.08s/step, loss: 2040.13818, cls loss: 4065.21802, reg loss: 15.05645\n",
      "Epoch: 0/50, step: 189/2141.0, 11.08s/step, loss: 2029.63440, cls loss: 4044.28955, reg loss: 14.97722\n",
      "Epoch: 0/50, step: 190/2141.0, 11.08s/step, loss: 2019.22937, cls loss: 4023.55762, reg loss: 14.89925\n",
      "Epoch: 0/50, step: 191/2141.0, 11.08s/step, loss: 2008.93958, cls loss: 4003.05566, reg loss: 14.82185\n",
      "Epoch: 0/50, step: 192/2141.0, 11.08s/step, loss: 1998.75305, cls loss: 3982.75830, reg loss: 14.74581\n",
      "Epoch: 0/50, step: 193/2141.0, 11.09s/step, loss: 1988.67273, cls loss: 3962.67358, reg loss: 14.66997\n",
      "Epoch: 0/50, step: 194/2141.0, 11.10s/step, loss: 1978.71106, cls loss: 3942.82080, reg loss: 14.59956\n",
      "Epoch: 0/50, step: 195/2141.0, 11.11s/step, loss: 1968.81079, cls loss: 3923.09473, reg loss: 14.52507\n",
      "Epoch: 0/50, step: 196/2141.0, 11.12s/step, loss: 1959.04626, cls loss: 3903.63892, reg loss: 14.45183\n",
      "Epoch: 0/50, step: 197/2141.0, 11.12s/step, loss: 1949.37329, cls loss: 3884.36548, reg loss: 14.37921\n",
      "Epoch: 0/50, step: 198/2141.0, 11.12s/step, loss: 1939.77258, cls loss: 3865.23584, reg loss: 14.30742\n",
      "Epoch: 0/50, step: 199/2141.0, 11.12s/step, loss: 1930.29541, cls loss: 3846.35254, reg loss: 14.23638\n",
      "Epoch: 0/50, step: 200/2141.0, 11.11s/step, loss: 1920.92102, cls loss: 3827.67383, reg loss: 14.16619\n",
      "Epoch: 0/50, step: 201/2141.0, 11.11s/step, loss: 1911.62463, cls loss: 3809.15137, reg loss: 14.09613\n",
      "Epoch: 0/50, step: 202/2141.0, 11.12s/step, loss: 1902.53186, cls loss: 3790.85254, reg loss: 14.20949\n",
      "Epoch: 0/50, step: 203/2141.0, 11.12s/step, loss: 1893.40039, cls loss: 3772.65894, reg loss: 14.14016\n",
      "Epoch: 0/50, step: 204/2141.0, 11.14s/step, loss: 1884.38037, cls loss: 3754.68604, reg loss: 14.07305\n",
      "Epoch: 0/50, step: 205/2141.0, 11.14s/step, loss: 1875.43396, cls loss: 3736.86084, reg loss: 14.00576\n",
      "Epoch: 0/50, step: 206/2141.0, 11.15s/step, loss: 1866.60291, cls loss: 3719.26367, reg loss: 13.94079\n",
      "Epoch: 0/50, step: 207/2141.0, 11.16s/step, loss: 1857.82300, cls loss: 3701.77051, reg loss: 13.87393\n",
      "Epoch: 0/50, step: 208/2141.0, 11.17s/step, loss: 1849.11755, cls loss: 3684.42114, reg loss: 13.81221\n",
      "Epoch: 0/50, step: 209/2141.0, 11.17s/step, loss: 1840.82471, cls loss: 3667.36963, reg loss: 14.27806\n",
      "Epoch: 0/50, step: 210/2141.0, 11.17s/step, loss: 1832.33484, cls loss: 3650.44043, reg loss: 14.22738\n",
      "Epoch: 0/50, step: 211/2141.0, 11.17s/step, loss: 1823.88574, cls loss: 3633.60889, reg loss: 14.16080\n",
      "Epoch: 0/50, step: 212/2141.0, 11.17s/step, loss: 1815.50171, cls loss: 3616.90674, reg loss: 14.09498\n",
      "Epoch: 0/50, step: 213/2141.0, 11.18s/step, loss: 1807.20532, cls loss: 3600.37891, reg loss: 14.02980\n",
      "Epoch: 0/50, step: 214/2141.0, 11.19s/step, loss: 1798.98755, cls loss: 3584.00781, reg loss: 13.96513\n",
      "Epoch: 0/50, step: 215/2141.0, 11.19s/step, loss: 1790.85364, cls loss: 3567.80371, reg loss: 13.90140\n",
      "Epoch: 0/50, step: 216/2141.0, 11.20s/step, loss: 1782.78076, cls loss: 3551.70068, reg loss: 13.85915\n",
      "Epoch: 0/50, step: 217/2141.0, 11.21s/step, loss: 1775.14258, cls loss: 3535.99829, reg loss: 14.28520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 218/2141.0, 11.21s/step, loss: 1767.21460, cls loss: 3520.19922, reg loss: 14.22830\n",
      "Epoch: 0/50, step: 219/2141.0, 11.22s/step, loss: 1759.33594, cls loss: 3504.50659, reg loss: 14.16385\n",
      "Epoch: 0/50, step: 220/2141.0, 11.22s/step, loss: 1751.55017, cls loss: 3488.99829, reg loss: 14.10068\n",
      "Epoch: 0/50, step: 221/2141.0, 11.23s/step, loss: 1743.82056, cls loss: 3473.60181, reg loss: 14.03767\n",
      "Epoch: 0/50, step: 222/2141.0, 11.23s/step, loss: 1736.16370, cls loss: 3458.35107, reg loss: 13.97486\n",
      "Epoch: 0/50, step: 223/2141.0, 11.25s/step, loss: 1728.58508, cls loss: 3443.25513, reg loss: 13.91377\n",
      "Epoch: 0/50, step: 224/2141.0, 11.26s/step, loss: 1721.06592, cls loss: 3428.27832, reg loss: 13.85204\n",
      "Epoch: 0/50, step: 225/2141.0, 11.27s/step, loss: 1713.61804, cls loss: 3413.44336, reg loss: 13.79111\n",
      "Epoch: 0/50, step: 226/2141.0, 11.27s/step, loss: 1706.21790, cls loss: 3398.70386, reg loss: 13.73052\n",
      "Epoch: 0/50, step: 227/2141.0, 11.27s/step, loss: 1698.91040, cls loss: 3384.14746, reg loss: 13.67168\n",
      "Epoch: 0/50, step: 228/2141.0, 11.28s/step, loss: 1691.64709, cls loss: 3369.67798, reg loss: 13.61458\n",
      "Epoch: 0/50, step: 229/2141.0, 11.29s/step, loss: 1684.46887, cls loss: 3355.37988, reg loss: 13.55633\n",
      "Epoch: 0/50, step: 230/2141.0, 11.30s/step, loss: 1677.34106, cls loss: 3341.18237, reg loss: 13.49820\n",
      "Epoch: 0/50, step: 231/2141.0, 11.30s/step, loss: 1670.27686, cls loss: 3327.11157, reg loss: 13.44077\n",
      "Epoch: 0/50, step: 232/2141.0, 11.30s/step, loss: 1663.26306, cls loss: 3313.14087, reg loss: 13.38412\n",
      "Epoch: 0/50, step: 233/2141.0, 11.31s/step, loss: 1656.29651, cls loss: 3299.26465, reg loss: 13.32701\n",
      "Epoch: 0/50, step: 234/2141.0, 11.31s/step, loss: 1649.41089, cls loss: 3285.54956, reg loss: 13.27107\n",
      "Epoch: 0/50, step: 235/2141.0, 11.32s/step, loss: 1642.66699, cls loss: 3271.97485, reg loss: 13.35778\n",
      "Epoch: 0/50, step: 236/2141.0, 11.32s/step, loss: 1635.88391, cls loss: 3258.46460, reg loss: 13.30174\n",
      "Epoch: 0/50, step: 237/2141.0, 11.35s/step, loss: 1629.20801, cls loss: 3245.15869, reg loss: 13.25573\n",
      "Epoch: 0/50, step: 238/2141.0, 11.35s/step, loss: 1622.52832, cls loss: 3231.85449, reg loss: 13.20050\n",
      "Epoch: 0/50, step: 239/2141.0, 11.35s/step, loss: 1615.92383, cls loss: 3218.69971, reg loss: 13.14629\n",
      "Epoch: 0/50, step: 240/2141.0, 11.36s/step, loss: 1609.36316, cls loss: 3205.63306, reg loss: 13.09180\n",
      "Epoch: 0/50, step: 241/2141.0, 11.37s/step, loss: 1602.84729, cls loss: 3192.65503, reg loss: 13.03784\n",
      "Epoch: 0/50, step: 242/2141.0, 11.37s/step, loss: 1596.54614, cls loss: 3179.87476, reg loss: 13.21591\n",
      "Epoch: 0/50, step: 243/2141.0, 11.37s/step, loss: 1590.14685, cls loss: 3167.12988, reg loss: 13.16223\n",
      "Epoch: 0/50, step: 244/2141.0, 11.37s/step, loss: 1583.79309, cls loss: 3154.47559, reg loss: 13.10891\n",
      "Epoch: 0/50, step: 245/2141.0, 11.37s/step, loss: 1577.56763, cls loss: 3141.94995, reg loss: 13.18325\n",
      "Epoch: 0/50, step: 246/2141.0, 11.38s/step, loss: 1571.30859, cls loss: 3129.48535, reg loss: 13.12988\n",
      "Epoch: 0/50, step: 247/2141.0, 11.38s/step, loss: 1565.11145, cls loss: 3117.14258, reg loss: 13.07815\n",
      "Epoch: 0/50, step: 248/2141.0, 11.38s/step, loss: 1558.95618, cls loss: 3104.88428, reg loss: 13.02616\n",
      "Epoch: 0/50, step: 249/2141.0, 11.39s/step, loss: 1552.86536, cls loss: 3092.75073, reg loss: 12.97810\n",
      "Epoch: 0/50, step: 250/2141.0, 11.39s/step, loss: 1546.82336, cls loss: 3080.71729, reg loss: 12.92755\n",
      "Epoch: 0/50, step: 251/2141.0, 11.39s/step, loss: 1540.81592, cls loss: 3068.75195, reg loss: 12.87811\n",
      "Epoch: 0/50, step: 252/2141.0, 11.39s/step, loss: 1534.92017, cls loss: 3056.93188, reg loss: 12.90680\n",
      "Epoch: 0/50, step: 253/2141.0, 11.40s/step, loss: 1529.00342, cls loss: 3045.14868, reg loss: 12.85638\n",
      "Epoch: 0/50, step: 254/2141.0, 11.39s/step, loss: 1523.14551, cls loss: 3033.47803, reg loss: 12.81116\n",
      "Epoch: 0/50, step: 255/2141.0, 11.39s/step, loss: 1517.33618, cls loss: 3021.90552, reg loss: 12.76485\n",
      "Epoch: 0/50, step: 256/2141.0, 11.39s/step, loss: 1511.55432, cls loss: 3010.39111, reg loss: 12.71568\n",
      "Epoch: 0/50, step: 257/2141.0, 11.38s/step, loss: 1505.81677, cls loss: 2998.96484, reg loss: 12.66662\n",
      "Epoch: 0/50, step: 258/2141.0, 11.38s/step, loss: 1500.11963, cls loss: 2987.61938, reg loss: 12.61784\n",
      "Epoch: 0/50, step: 259/2141.0, 11.38s/step, loss: 1494.47791, cls loss: 2976.38428, reg loss: 12.56956\n",
      "Epoch: 0/50, step: 260/2141.0, 11.37s/step, loss: 1488.87427, cls loss: 2965.22339, reg loss: 12.52329\n",
      "Epoch: 0/50, step: 261/2141.0, 11.37s/step, loss: 1483.33374, cls loss: 2954.18237, reg loss: 12.48312\n",
      "Epoch: 0/50, step: 262/2141.0, 11.37s/step, loss: 1477.80811, cls loss: 2943.17822, reg loss: 12.43633\n",
      "Epoch: 0/50, step: 263/2141.0, 11.37s/step, loss: 1472.31799, cls loss: 2932.24512, reg loss: 12.38925\n",
      "Epoch: 0/50, step: 264/2141.0, 11.37s/step, loss: 1466.91553, cls loss: 2921.41943, reg loss: 12.41026\n",
      "Epoch: 0/50, step: 265/2141.0, 11.37s/step, loss: 1461.52600, cls loss: 2910.68433, reg loss: 12.36620\n",
      "Epoch: 0/50, step: 266/2141.0, 11.37s/step, loss: 1456.17383, cls loss: 2900.02588, reg loss: 12.32018\n",
      "Epoch: 0/50, step: 267/2141.0, 11.37s/step, loss: 1450.85034, cls loss: 2889.42480, reg loss: 12.27439\n",
      "Epoch: 0/50, step: 268/2141.0, 11.37s/step, loss: 1445.58752, cls loss: 2878.93140, reg loss: 12.24219\n",
      "Epoch: 0/50, step: 269/2141.0, 11.36s/step, loss: 1440.36267, cls loss: 2868.52686, reg loss: 12.19727\n",
      "Epoch: 0/50, step: 270/2141.0, 11.36s/step, loss: 1435.18066, cls loss: 2858.20679, reg loss: 12.15304\n",
      "Epoch: 0/50, step: 271/2141.0, 11.37s/step, loss: 1430.04236, cls loss: 2847.96753, reg loss: 12.11585\n",
      "Epoch: 0/50, step: 272/2141.0, 11.37s/step, loss: 1424.92139, cls loss: 2837.76978, reg loss: 12.07169\n",
      "Epoch: 0/50, step: 273/2141.0, 11.37s/step, loss: 1419.83069, cls loss: 2827.63232, reg loss: 12.02778\n",
      "Epoch: 0/50, step: 274/2141.0, 11.37s/step, loss: 1414.79443, cls loss: 2817.60278, reg loss: 11.98494\n",
      "Epoch: 0/50, step: 275/2141.0, 11.38s/step, loss: 1409.77197, cls loss: 2807.60083, reg loss: 11.94192\n",
      "Epoch: 0/50, step: 276/2141.0, 11.39s/step, loss: 1404.80164, cls loss: 2797.70215, reg loss: 11.89985\n",
      "Epoch: 0/50, step: 277/2141.0, 11.39s/step, loss: 1399.86072, cls loss: 2787.86206, reg loss: 11.85827\n",
      "Epoch: 0/50, step: 278/2141.0, 11.39s/step, loss: 1394.95032, cls loss: 2778.08276, reg loss: 11.81627\n",
      "Epoch: 0/50, step: 279/2141.0, 11.39s/step, loss: 1390.07483, cls loss: 2768.37378, reg loss: 11.77450\n",
      "Epoch: 0/50, step: 280/2141.0, 11.39s/step, loss: 1385.23035, cls loss: 2758.72632, reg loss: 11.73304\n",
      "Epoch: 0/50, step: 281/2141.0, 11.39s/step, loss: 1380.41614, cls loss: 2749.13892, reg loss: 11.69176\n",
      "Epoch: 0/50, step: 282/2141.0, 11.39s/step, loss: 1375.67236, cls loss: 2739.67407, reg loss: 11.66924\n",
      "Epoch: 0/50, step: 283/2141.0, 11.39s/step, loss: 1370.93787, cls loss: 2730.23999, reg loss: 11.63419\n",
      "Epoch: 0/50, step: 284/2141.0, 11.39s/step, loss: 1366.27734, cls loss: 2720.89990, reg loss: 11.65338\n",
      "Epoch: 0/50, step: 285/2141.0, 11.38s/step, loss: 1361.60266, cls loss: 2711.59058, reg loss: 11.61358\n",
      "Epoch: 0/50, step: 286/2141.0, 11.38s/step, loss: 1356.95483, cls loss: 2702.33472, reg loss: 11.57350\n",
      "Epoch: 0/50, step: 287/2141.0, 11.38s/step, loss: 1352.34082, cls loss: 2693.14648, reg loss: 11.53381\n",
      "Epoch: 0/50, step: 288/2141.0, 11.38s/step, loss: 1347.75952, cls loss: 2684.02368, reg loss: 11.49421\n",
      "Epoch: 0/50, step: 289/2141.0, 11.39s/step, loss: 1343.21484, cls loss: 2674.97363, reg loss: 11.45477\n",
      "Epoch: 0/50, step: 290/2141.0, 11.39s/step, loss: 1338.68835, cls loss: 2665.95996, reg loss: 11.41540\n",
      "Epoch: 0/50, step: 291/2141.0, 11.39s/step, loss: 1334.19922, cls loss: 2657.02002, reg loss: 11.37695\n",
      "Epoch: 0/50, step: 292/2141.0, 11.39s/step, loss: 1329.74622, cls loss: 2648.15283, reg loss: 11.33859\n",
      "Epoch: 0/50, step: 293/2141.0, 11.40s/step, loss: 1325.36365, cls loss: 2639.35181, reg loss: 11.37435\n",
      "Epoch: 0/50, step: 294/2141.0, 11.40s/step, loss: 1320.95959, cls loss: 2630.58154, reg loss: 11.33664\n",
      "Epoch: 0/50, step: 295/2141.0, 11.41s/step, loss: 1316.59265, cls loss: 2621.88525, reg loss: 11.29900\n",
      "Epoch: 0/50, step: 296/2141.0, 11.41s/step, loss: 1312.26099, cls loss: 2613.25781, reg loss: 11.26313\n",
      "Epoch: 0/50, step: 297/2141.0, 11.41s/step, loss: 1308.10388, cls loss: 2604.72241, reg loss: 11.48427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 298/2141.0, 11.41s/step, loss: 1303.82666, cls loss: 2596.20557, reg loss: 11.44635\n",
      "Epoch: 0/50, step: 299/2141.0, 11.43s/step, loss: 1299.61755, cls loss: 2587.77905, reg loss: 11.45457\n",
      "Epoch: 0/50, step: 300/2141.0, 11.43s/step, loss: 1295.39294, cls loss: 2579.36792, reg loss: 11.41670\n",
      "Epoch: 0/50, step: 301/2141.0, 11.43s/step, loss: 1291.21704, cls loss: 2571.05249, reg loss: 11.38038\n",
      "Epoch: 0/50, step: 302/2141.0, 11.42s/step, loss: 1287.04419, cls loss: 2562.74390, reg loss: 11.34300\n",
      "Epoch: 0/50, step: 303/2141.0, 11.42s/step, loss: 1282.91565, cls loss: 2554.50586, reg loss: 11.32414\n",
      "Epoch: 0/50, step: 304/2141.0, 11.42s/step, loss: 1278.80359, cls loss: 2546.31836, reg loss: 11.28763\n",
      "Epoch: 0/50, step: 305/2141.0, 11.42s/step, loss: 1274.72485, cls loss: 2538.19702, reg loss: 11.25137\n",
      "Epoch: 0/50, step: 306/2141.0, 11.42s/step, loss: 1270.67786, cls loss: 2530.13867, reg loss: 11.21572\n",
      "Epoch: 0/50, step: 307/2141.0, 11.42s/step, loss: 1266.64392, cls loss: 2522.10449, reg loss: 11.18217\n",
      "Epoch: 0/50, step: 308/2141.0, 11.42s/step, loss: 1262.63159, cls loss: 2514.11475, reg loss: 11.14716\n",
      "Epoch: 0/50, step: 309/2141.0, 11.43s/step, loss: 1258.64270, cls loss: 2506.17261, reg loss: 11.11176\n",
      "Epoch: 0/50, step: 310/2141.0, 11.42s/step, loss: 1254.67590, cls loss: 2498.27417, reg loss: 11.07659\n",
      "Epoch: 0/50, step: 311/2141.0, 11.43s/step, loss: 1250.73889, cls loss: 2490.43481, reg loss: 11.04173\n",
      "Epoch: 0/50, step: 312/2141.0, 11.43s/step, loss: 1246.84180, cls loss: 2482.67480, reg loss: 11.00771\n",
      "Epoch: 0/50, step: 313/2141.0, 11.43s/step, loss: 1242.94971, cls loss: 2474.92529, reg loss: 10.97293\n",
      "Epoch: 0/50, step: 314/2141.0, 11.43s/step, loss: 1239.07983, cls loss: 2467.22021, reg loss: 10.93828\n",
      "Epoch: 0/50, step: 315/2141.0, 11.43s/step, loss: 1235.24194, cls loss: 2459.57837, reg loss: 10.90418\n",
      "Epoch: 0/50, step: 316/2141.0, 11.42s/step, loss: 1231.42810, cls loss: 2451.98413, reg loss: 10.87072\n",
      "Epoch: 0/50, step: 317/2141.0, 11.42s/step, loss: 1227.65845, cls loss: 2444.47754, reg loss: 10.83778\n",
      "Epoch: 0/50, step: 318/2141.0, 11.42s/step, loss: 1223.90845, cls loss: 2437.00269, reg loss: 10.81278\n",
      "Epoch: 0/50, step: 319/2141.0, 11.42s/step, loss: 1220.16516, cls loss: 2429.54956, reg loss: 10.77906\n",
      "Epoch: 0/50, step: 320/2141.0, 11.41s/step, loss: 1216.44385, cls loss: 2422.13989, reg loss: 10.74610\n",
      "Epoch: 0/50, step: 321/2141.0, 11.43s/step, loss: 1212.74255, cls loss: 2414.77075, reg loss: 10.71277\n",
      "Epoch: 0/50, step: 322/2141.0, 11.43s/step, loss: 1209.06592, cls loss: 2407.44971, reg loss: 10.68045\n",
      "Epoch: 0/50, step: 323/2141.0, 11.43s/step, loss: 1205.42029, cls loss: 2400.19092, reg loss: 10.64787\n",
      "Epoch: 0/50, step: 324/2141.0, 11.43s/step, loss: 1201.78943, cls loss: 2392.96167, reg loss: 10.61561\n",
      "Epoch: 0/50, step: 325/2141.0, 11.43s/step, loss: 1198.17883, cls loss: 2385.77295, reg loss: 10.58335\n",
      "Epoch: 0/50, step: 326/2141.0, 11.43s/step, loss: 1194.58264, cls loss: 2378.61304, reg loss: 10.55111\n",
      "Epoch: 0/50, step: 327/2141.0, 11.43s/step, loss: 1191.01672, cls loss: 2371.51294, reg loss: 10.51912\n",
      "Epoch: 0/50, step: 328/2141.0, 11.43s/step, loss: 1187.47986, cls loss: 2364.47119, reg loss: 10.48733\n",
      "Epoch: 0/50, step: 329/2141.0, 11.44s/step, loss: 1183.96094, cls loss: 2357.46338, reg loss: 10.45704\n",
      "Epoch: 0/50, step: 330/2141.0, 11.45s/step, loss: 1180.45422, cls loss: 2350.48145, reg loss: 10.42562\n",
      "Epoch: 0/50, step: 331/2141.0, 11.45s/step, loss: 1177.07434, cls loss: 2343.62451, reg loss: 10.52296\n",
      "Epoch: 0/50, step: 332/2141.0, 11.45s/step, loss: 1173.62073, cls loss: 2336.74805, reg loss: 10.49235\n",
      "Epoch: 0/50, step: 333/2141.0, 11.45s/step, loss: 1170.19592, cls loss: 2329.91797, reg loss: 10.47271\n",
      "Epoch: 0/50, step: 334/2141.0, 11.45s/step, loss: 1166.77551, cls loss: 2323.10767, reg loss: 10.44248\n",
      "Epoch: 0/50, step: 335/2141.0, 11.44s/step, loss: 1163.41809, cls loss: 2316.35181, reg loss: 10.48336\n",
      "Epoch: 0/50, step: 336/2141.0, 11.44s/step, loss: 1160.03064, cls loss: 2309.60693, reg loss: 10.45366\n",
      "Epoch: 0/50, step: 337/2141.0, 11.44s/step, loss: 1156.67554, cls loss: 2302.92554, reg loss: 10.42455\n",
      "Epoch: 0/50, step: 338/2141.0, 11.44s/step, loss: 1153.32922, cls loss: 2296.26367, reg loss: 10.39400\n",
      "Epoch: 0/50, step: 339/2141.0, 11.44s/step, loss: 1150.00415, cls loss: 2289.64380, reg loss: 10.36357\n",
      "Epoch: 0/50, step: 340/2141.0, 11.44s/step, loss: 1146.70776, cls loss: 2283.08105, reg loss: 10.33362\n",
      "Epoch: 0/50, step: 341/2141.0, 11.43s/step, loss: 1143.42456, cls loss: 2276.54443, reg loss: 10.30396\n",
      "Epoch: 0/50, step: 342/2141.0, 11.43s/step, loss: 1140.18384, cls loss: 2270.08936, reg loss: 10.27748\n",
      "Epoch: 0/50, step: 343/2141.0, 11.43s/step, loss: 1136.94055, cls loss: 2263.63257, reg loss: 10.24787\n",
      "Epoch: 0/50, step: 344/2141.0, 11.43s/step, loss: 1133.72058, cls loss: 2257.22192, reg loss: 10.21832\n",
      "Epoch: 0/50, step: 345/2141.0, 11.43s/step, loss: 1130.52588, cls loss: 2250.86084, reg loss: 10.19036\n",
      "Epoch: 0/50, step: 346/2141.0, 11.43s/step, loss: 1127.33777, cls loss: 2244.51343, reg loss: 10.16145\n",
      "Epoch: 0/50, step: 347/2141.0, 11.43s/step, loss: 1124.16357, cls loss: 2238.19336, reg loss: 10.13289\n",
      "Epoch: 0/50, step: 348/2141.0, 11.43s/step, loss: 1121.00635, cls loss: 2231.90771, reg loss: 10.10412\n",
      "Epoch: 0/50, step: 349/2141.0, 11.43s/step, loss: 1117.86597, cls loss: 2225.65576, reg loss: 10.07549\n",
      "Epoch: 0/50, step: 350/2141.0, 11.42s/step, loss: 1114.74854, cls loss: 2219.44922, reg loss: 10.04712\n",
      "Epoch: 0/50, step: 351/2141.0, 11.43s/step, loss: 1111.67273, cls loss: 2213.32251, reg loss: 10.02202\n",
      "Epoch: 0/50, step: 352/2141.0, 11.42s/step, loss: 1108.58984, cls loss: 2207.18530, reg loss: 9.99371\n",
      "Epoch: 0/50, step: 353/2141.0, 11.42s/step, loss: 1105.52246, cls loss: 2201.07812, reg loss: 9.96586\n",
      "Epoch: 0/50, step: 354/2141.0, 11.42s/step, loss: 1102.46411, cls loss: 2194.98926, reg loss: 9.93806\n",
      "Epoch: 0/50, step: 355/2141.0, 11.42s/step, loss: 1099.44043, cls loss: 2188.96899, reg loss: 9.91080\n",
      "Epoch: 0/50, step: 356/2141.0, 11.41s/step, loss: 1096.42249, cls loss: 2182.96069, reg loss: 9.88335\n",
      "Epoch: 0/50, step: 357/2141.0, 11.41s/step, loss: 1093.42981, cls loss: 2177.00220, reg loss: 9.85651\n",
      "Epoch: 0/50, step: 358/2141.0, 11.41s/step, loss: 1090.45190, cls loss: 2171.07324, reg loss: 9.82972\n",
      "Epoch: 0/50, step: 359/2141.0, 11.41s/step, loss: 1087.48560, cls loss: 2165.16748, reg loss: 9.80291\n",
      "Epoch: 0/50, step: 360/2141.0, 11.40s/step, loss: 1084.53760, cls loss: 2159.29834, reg loss: 9.77595\n",
      "Epoch: 0/50, step: 361/2141.0, 11.41s/step, loss: 1081.60840, cls loss: 2153.46680, reg loss: 9.74926\n",
      "Epoch: 0/50, step: 362/2141.0, 11.40s/step, loss: 1078.69165, cls loss: 2147.65942, reg loss: 9.72291\n",
      "Epoch: 0/50, step: 363/2141.0, 11.40s/step, loss: 1075.80688, cls loss: 2141.91235, reg loss: 9.70042\n",
      "Epoch: 0/50, step: 364/2141.0, 11.41s/step, loss: 1072.96973, cls loss: 2136.24683, reg loss: 9.69199\n",
      "Epoch: 0/50, step: 365/2141.0, 11.41s/step, loss: 1070.10095, cls loss: 2130.53491, reg loss: 9.66606\n",
      "Epoch: 0/50, step: 366/2141.0, 11.41s/step, loss: 1067.24988, cls loss: 2124.85889, reg loss: 9.63998\n",
      "Epoch: 0/50, step: 367/2141.0, 11.40s/step, loss: 1064.40918, cls loss: 2119.20312, reg loss: 9.61437\n",
      "Epoch: 0/50, step: 368/2141.0, 11.41s/step, loss: 1061.59131, cls loss: 2113.59253, reg loss: 9.58899\n",
      "Epoch: 0/50, step: 369/2141.0, 11.41s/step, loss: 1058.79797, cls loss: 2108.03052, reg loss: 9.56448\n",
      "Epoch: 0/50, step: 370/2141.0, 11.42s/step, loss: 1056.07312, cls loss: 2102.51904, reg loss: 9.62634\n",
      "Epoch: 0/50, step: 371/2141.0, 11.41s/step, loss: 1053.29614, cls loss: 2096.99048, reg loss: 9.60084\n",
      "Epoch: 0/50, step: 372/2141.0, 11.41s/step, loss: 1050.53540, cls loss: 2091.49438, reg loss: 9.57539\n",
      "Epoch: 0/50, step: 373/2141.0, 11.42s/step, loss: 1047.79309, cls loss: 2086.03442, reg loss: 9.55061\n",
      "Epoch: 0/50, step: 374/2141.0, 11.41s/step, loss: 1045.05347, cls loss: 2080.58032, reg loss: 9.52565\n",
      "Epoch: 0/50, step: 375/2141.0, 11.42s/step, loss: 1042.34387, cls loss: 2075.17993, reg loss: 9.50650\n",
      "Epoch: 0/50, step: 376/2141.0, 11.41s/step, loss: 1039.63416, cls loss: 2069.78589, reg loss: 9.48147\n",
      "Epoch: 0/50, step: 377/2141.0, 11.41s/step, loss: 1036.94604, cls loss: 2064.43408, reg loss: 9.45691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 378/2141.0, 11.42s/step, loss: 1034.27576, cls loss: 2059.11792, reg loss: 9.43233\n",
      "Epoch: 0/50, step: 379/2141.0, 11.42s/step, loss: 1031.61511, cls loss: 2053.82080, reg loss: 9.40806\n",
      "Epoch: 0/50, step: 380/2141.0, 11.42s/step, loss: 1028.96265, cls loss: 2048.54028, reg loss: 9.38377\n",
      "Epoch: 0/50, step: 381/2141.0, 11.42s/step, loss: 1026.35083, cls loss: 2043.31824, reg loss: 9.38196\n",
      "Epoch: 0/50, step: 382/2141.0, 11.43s/step, loss: 1023.72632, cls loss: 2038.09314, reg loss: 9.35803\n",
      "Epoch: 0/50, step: 383/2141.0, 11.43s/step, loss: 1021.11859, cls loss: 2032.90186, reg loss: 9.33382\n",
      "Epoch: 0/50, step: 384/2141.0, 11.44s/step, loss: 1018.52094, cls loss: 2027.73022, reg loss: 9.31032\n",
      "Epoch: 0/50, step: 385/2141.0, 11.44s/step, loss: 1015.93823, cls loss: 2022.58862, reg loss: 9.28649\n",
      "Epoch: 0/50, step: 386/2141.0, 11.43s/step, loss: 1013.37451, cls loss: 2017.48389, reg loss: 9.26373\n",
      "Epoch: 0/50, step: 387/2141.0, 11.43s/step, loss: 1010.81354, cls loss: 2012.38562, reg loss: 9.24003\n",
      "Epoch: 0/50, step: 388/2141.0, 11.43s/step, loss: 1008.29724, cls loss: 2007.36133, reg loss: 9.23170\n",
      "Epoch: 0/50, step: 389/2141.0, 11.43s/step, loss: 1005.76520, cls loss: 2002.32031, reg loss: 9.20867\n",
      "Epoch: 0/50, step: 390/2141.0, 11.43s/step, loss: 1003.25586, cls loss: 1997.32190, reg loss: 9.18826\n",
      "Epoch: 0/50, step: 391/2141.0, 11.43s/step, loss: 1000.74982, cls loss: 1992.33240, reg loss: 9.16583\n",
      "Epoch: 0/50, step: 392/2141.0, 11.42s/step, loss: 998.25635, cls loss: 1987.36877, reg loss: 9.14262\n",
      "Epoch: 0/50, step: 393/2141.0, 11.42s/step, loss: 995.77466, cls loss: 1982.42834, reg loss: 9.11979\n",
      "Epoch: 0/50, step: 394/2141.0, 11.43s/step, loss: 993.30859, cls loss: 1977.51819, reg loss: 9.09776\n",
      "Epoch: 0/50, step: 395/2141.0, 11.43s/step, loss: 990.85919, cls loss: 1972.64209, reg loss: 9.07519\n",
      "Epoch: 0/50, step: 396/2141.0, 11.44s/step, loss: 988.41382, cls loss: 1967.77393, reg loss: 9.05251\n",
      "Epoch: 0/50, step: 397/2141.0, 11.44s/step, loss: 985.97388, cls loss: 1962.91675, reg loss: 9.02976\n",
      "Epoch: 0/50, step: 398/2141.0, 11.44s/step, loss: 983.54865, cls loss: 1958.08899, reg loss: 9.00719\n",
      "Epoch: 0/50, step: 399/2141.0, 11.44s/step, loss: 981.15735, cls loss: 1953.32410, reg loss: 8.98943\n",
      "Epoch: 0/50, step: 400/2141.0, 11.45s/step, loss: 978.78802, cls loss: 1948.60522, reg loss: 8.96964\n",
      "Epoch: 0/50, step: 401/2141.0, 11.45s/step, loss: 976.39722, cls loss: 1943.84595, reg loss: 8.94732\n",
      "Epoch: 0/50, step: 402/2141.0, 11.45s/step, loss: 974.06458, cls loss: 1939.14172, reg loss: 8.98630\n",
      "Epoch: 0/50, step: 403/2141.0, 11.45s/step, loss: 971.70319, cls loss: 1934.44104, reg loss: 8.96425\n",
      "Epoch: 0/50, step: 404/2141.0, 11.45s/step, loss: 969.35730, cls loss: 1929.76001, reg loss: 8.95346\n",
      "Epoch: 0/50, step: 405/2141.0, 11.45s/step, loss: 967.02930, cls loss: 1925.12500, reg loss: 8.93236\n",
      "Epoch: 0/50, step: 406/2141.0, 11.45s/step, loss: 964.70087, cls loss: 1920.48975, reg loss: 8.91061\n",
      "Epoch: 0/50, step: 407/2141.0, 11.45s/step, loss: 962.38574, cls loss: 1915.88086, reg loss: 8.88930\n",
      "Epoch: 0/50, step: 408/2141.0, 11.45s/step, loss: 960.09424, cls loss: 1911.31445, reg loss: 8.87263\n",
      "Epoch: 0/50, step: 409/2141.0, 11.45s/step, loss: 957.80463, cls loss: 1906.75598, reg loss: 8.85198\n",
      "Epoch: 0/50, step: 410/2141.0, 11.45s/step, loss: 955.52454, cls loss: 1902.21667, reg loss: 8.83110\n",
      "Epoch: 0/50, step: 411/2141.0, 11.45s/step, loss: 953.24896, cls loss: 1897.68677, reg loss: 8.80975\n",
      "Epoch: 0/50, step: 412/2141.0, 11.45s/step, loss: 950.99518, cls loss: 1893.19995, reg loss: 8.78899\n",
      "Epoch: 0/50, step: 413/2141.0, 11.45s/step, loss: 948.75763, cls loss: 1888.74365, reg loss: 8.77014\n",
      "Epoch: 0/50, step: 414/2141.0, 11.45s/step, loss: 946.52002, cls loss: 1884.28955, reg loss: 8.74910\n",
      "Epoch: 0/50, step: 415/2141.0, 11.45s/step, loss: 944.28650, cls loss: 1879.84363, reg loss: 8.72807\n",
      "Epoch: 0/50, step: 416/2141.0, 11.47s/step, loss: 942.07465, cls loss: 1875.44019, reg loss: 8.70778\n",
      "Epoch: 0/50, step: 417/2141.0, 11.47s/step, loss: 939.87189, cls loss: 1871.05542, reg loss: 8.68700\n",
      "Epoch: 0/50, step: 418/2141.0, 11.47s/step, loss: 937.67572, cls loss: 1866.68359, reg loss: 8.66651\n",
      "Epoch: 0/50, step: 419/2141.0, 11.47s/step, loss: 935.49097, cls loss: 1862.33435, reg loss: 8.64622\n",
      "Epoch: 0/50, step: 420/2141.0, 11.47s/step, loss: 933.32422, cls loss: 1858.02014, reg loss: 8.62687\n",
      "Epoch: 0/50, step: 421/2141.0, 11.47s/step, loss: 931.16174, cls loss: 1853.71436, reg loss: 8.60765\n",
      "Epoch: 0/50, step: 422/2141.0, 11.47s/step, loss: 929.00885, cls loss: 1849.42847, reg loss: 8.58781\n",
      "Epoch: 0/50, step: 423/2141.0, 11.47s/step, loss: 926.85712, cls loss: 1845.14502, reg loss: 8.56767\n",
      "Epoch: 0/50, step: 424/2141.0, 11.47s/step, loss: 924.72076, cls loss: 1840.89221, reg loss: 8.54789\n",
      "Epoch: 0/50, step: 425/2141.0, 11.47s/step, loss: 922.60767, cls loss: 1836.68469, reg loss: 8.52934\n",
      "Epoch: 0/50, step: 426/2141.0, 11.48s/step, loss: 920.50378, cls loss: 1832.49280, reg loss: 8.51349\n",
      "Epoch: 0/50, step: 427/2141.0, 11.48s/step, loss: 918.40637, cls loss: 1828.31519, reg loss: 8.49637\n",
      "Epoch: 0/50, step: 428/2141.0, 11.48s/step, loss: 916.30859, cls loss: 1824.13916, reg loss: 8.47665\n",
      "Epoch: 0/50, step: 429/2141.0, 11.48s/step, loss: 914.22089, cls loss: 1819.98315, reg loss: 8.45734\n",
      "Epoch: 0/50, step: 430/2141.0, 11.47s/step, loss: 912.14661, cls loss: 1815.85291, reg loss: 8.43893\n",
      "Epoch: 0/50, step: 431/2141.0, 11.47s/step, loss: 910.07886, cls loss: 1811.73621, reg loss: 8.42015\n",
      "Epoch: 0/50, step: 432/2141.0, 11.47s/step, loss: 908.02972, cls loss: 1807.65051, reg loss: 8.40768\n",
      "Epoch: 0/50, step: 433/2141.0, 11.47s/step, loss: 905.98090, cls loss: 1803.57190, reg loss: 8.38883\n",
      "Epoch: 0/50, step: 434/2141.0, 11.47s/step, loss: 903.96790, cls loss: 1799.53271, reg loss: 8.40185\n",
      "Epoch: 0/50, step: 435/2141.0, 11.47s/step, loss: 901.94293, cls loss: 1795.50134, reg loss: 8.38337\n",
      "Epoch: 0/50, step: 436/2141.0, 11.47s/step, loss: 899.94714, cls loss: 1791.52112, reg loss: 8.37192\n",
      "Epoch: 0/50, step: 437/2141.0, 11.47s/step, loss: 897.94427, cls loss: 1787.52808, reg loss: 8.35927\n",
      "Epoch: 0/50, step: 438/2141.0, 11.47s/step, loss: 895.94055, cls loss: 1783.53918, reg loss: 8.34076\n",
      "Epoch: 0/50, step: 439/2141.0, 11.47s/step, loss: 893.94934, cls loss: 1779.57495, reg loss: 8.32253\n",
      "Epoch: 0/50, step: 440/2141.0, 11.47s/step, loss: 891.95959, cls loss: 1775.61426, reg loss: 8.30378\n",
      "Epoch: 0/50, step: 441/2141.0, 11.47s/step, loss: 889.98657, cls loss: 1771.68640, reg loss: 8.28552\n",
      "Epoch: 0/50, step: 442/2141.0, 11.47s/step, loss: 888.02203, cls loss: 1767.77515, reg loss: 8.26769\n",
      "Epoch: 0/50, step: 443/2141.0, 11.47s/step, loss: 886.06506, cls loss: 1763.87952, reg loss: 8.24928\n",
      "Epoch: 0/50, step: 444/2141.0, 11.47s/step, loss: 884.10852, cls loss: 1759.98499, reg loss: 8.23087\n",
      "Epoch: 0/50, step: 445/2141.0, 11.47s/step, loss: 882.15997, cls loss: 1756.10620, reg loss: 8.21256\n",
      "Epoch: 0/50, step: 446/2141.0, 11.47s/step, loss: 880.22827, cls loss: 1752.26062, reg loss: 8.19465\n",
      "Epoch: 0/50, step: 447/2141.0, 11.46s/step, loss: 878.33051, cls loss: 1748.44324, reg loss: 8.21663\n",
      "Epoch: 0/50, step: 448/2141.0, 11.46s/step, loss: 876.41187, cls loss: 1744.62329, reg loss: 8.19932\n",
      "Epoch: 0/50, step: 449/2141.0, 11.46s/step, loss: 874.50201, cls loss: 1740.82166, reg loss: 8.18120\n",
      "Epoch: 0/50, step: 450/2141.0, 11.46s/step, loss: 872.61322, cls loss: 1737.06018, reg loss: 8.16517\n",
      "Epoch: 0/50, step: 451/2141.0, 11.46s/step, loss: 870.71802, cls loss: 1733.28735, reg loss: 8.14745\n",
      "Epoch: 0/50, step: 452/2141.0, 11.46s/step, loss: 868.83527, cls loss: 1729.53931, reg loss: 8.13006\n",
      "Epoch: 0/50, step: 453/2141.0, 11.47s/step, loss: 866.96637, cls loss: 1725.81836, reg loss: 8.11306\n",
      "Epoch: 0/50, step: 454/2141.0, 11.47s/step, loss: 865.09613, cls loss: 1722.09558, reg loss: 8.09551\n",
      "Epoch: 0/50, step: 455/2141.0, 11.47s/step, loss: 863.23047, cls loss: 1718.38196, reg loss: 8.07782\n",
      "Epoch: 0/50, step: 456/2141.0, 11.47s/step, loss: 861.37683, cls loss: 1714.69226, reg loss: 8.06027\n",
      "Epoch: 0/50, step: 457/2141.0, 11.47s/step, loss: 859.53564, cls loss: 1711.02698, reg loss: 8.04311\n",
      "Epoch: 0/50, step: 458/2141.0, 11.48s/step, loss: 857.70258, cls loss: 1707.37817, reg loss: 8.02597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 459/2141.0, 11.48s/step, loss: 855.88007, cls loss: 1703.74963, reg loss: 8.00955\n",
      "Epoch: 0/50, step: 460/2141.0, 11.48s/step, loss: 854.06104, cls loss: 1700.12720, reg loss: 7.99379\n",
      "Epoch: 0/50, step: 461/2141.0, 11.48s/step, loss: 852.25085, cls loss: 1696.52319, reg loss: 7.97759\n",
      "Epoch: 0/50, step: 462/2141.0, 11.48s/step, loss: 850.44434, cls loss: 1692.92712, reg loss: 7.96052\n",
      "Epoch: 0/50, step: 463/2141.0, 11.48s/step, loss: 848.64673, cls loss: 1689.34851, reg loss: 7.94397\n",
      "Epoch: 0/50, step: 464/2141.0, 11.49s/step, loss: 846.86597, cls loss: 1685.80322, reg loss: 7.92761\n",
      "Epoch: 0/50, step: 465/2141.0, 11.49s/step, loss: 845.08691, cls loss: 1682.26208, reg loss: 7.91067\n",
      "Epoch: 0/50, step: 466/2141.0, 11.50s/step, loss: 843.32251, cls loss: 1678.74902, reg loss: 7.89482\n",
      "Epoch: 0/50, step: 467/2141.0, 11.50s/step, loss: 841.56830, cls loss: 1675.24890, reg loss: 7.88650\n",
      "Epoch: 0/50, step: 468/2141.0, 11.50s/step, loss: 839.81018, cls loss: 1671.74915, reg loss: 7.86995\n",
      "Epoch: 0/50, step: 469/2141.0, 11.51s/step, loss: 838.05762, cls loss: 1668.26050, reg loss: 7.85362\n",
      "Epoch: 0/50, step: 470/2141.0, 11.50s/step, loss: 836.31970, cls loss: 1664.80127, reg loss: 7.83712\n",
      "Epoch: 0/50, step: 471/2141.0, 11.51s/step, loss: 834.59204, cls loss: 1661.36194, reg loss: 7.82104\n",
      "Epoch: 0/50, step: 472/2141.0, 11.51s/step, loss: 832.87213, cls loss: 1657.93811, reg loss: 7.80499\n",
      "Epoch: 0/50, step: 473/2141.0, 11.51s/step, loss: 831.15033, cls loss: 1654.51086, reg loss: 7.78867\n",
      "Epoch: 0/50, step: 474/2141.0, 11.52s/step, loss: 829.44177, cls loss: 1651.10913, reg loss: 7.77329\n",
      "Epoch: 0/50, step: 475/2141.0, 11.53s/step, loss: 827.72986, cls loss: 1647.70129, reg loss: 7.75721\n",
      "Epoch: 0/50, step: 476/2141.0, 11.54s/step, loss: 826.03448, cls loss: 1644.32605, reg loss: 7.74178\n",
      "Epoch: 0/50, step: 477/2141.0, 11.53s/step, loss: 824.34741, cls loss: 1640.96729, reg loss: 7.72633\n",
      "Epoch: 0/50, step: 478/2141.0, 11.53s/step, loss: 822.66461, cls loss: 1637.61743, reg loss: 7.71060\n",
      "Epoch: 0/50, step: 479/2141.0, 11.53s/step, loss: 820.98395, cls loss: 1634.27197, reg loss: 7.69469\n",
      "Epoch: 0/50, step: 480/2141.0, 11.54s/step, loss: 819.30872, cls loss: 1630.93750, reg loss: 7.67879\n",
      "Epoch: 0/50, step: 481/2141.0, 11.54s/step, loss: 817.64343, cls loss: 1627.62268, reg loss: 7.66297\n",
      "Epoch: 0/50, step: 482/2141.0, 11.54s/step, loss: 815.98999, cls loss: 1624.33057, reg loss: 7.64814\n",
      "Epoch: 0/50, step: 483/2141.0, 11.55s/step, loss: 814.33710, cls loss: 1621.03931, reg loss: 7.63383\n",
      "Epoch: 0/50, step: 484/2141.0, 11.55s/step, loss: 812.69055, cls loss: 1617.76147, reg loss: 7.61849\n",
      "Epoch: 0/50, step: 485/2141.0, 11.56s/step, loss: 811.05103, cls loss: 1614.49805, reg loss: 7.60296\n",
      "Epoch: 0/50, step: 486/2141.0, 11.56s/step, loss: 809.41876, cls loss: 1611.24890, reg loss: 7.58760\n",
      "Epoch: 0/50, step: 487/2141.0, 11.56s/step, loss: 807.78790, cls loss: 1608.00256, reg loss: 7.57215\n",
      "Epoch: 0/50, step: 488/2141.0, 11.55s/step, loss: 806.16949, cls loss: 1604.78076, reg loss: 7.55708\n",
      "Epoch: 0/50, step: 489/2141.0, 11.55s/step, loss: 804.55603, cls loss: 1601.56921, reg loss: 7.54181\n",
      "Epoch: 0/50, step: 490/2141.0, 11.55s/step, loss: 802.95294, cls loss: 1598.37805, reg loss: 7.52686\n",
      "Epoch: 0/50, step: 491/2141.0, 11.55s/step, loss: 801.35205, cls loss: 1595.19128, reg loss: 7.51182\n",
      "Epoch: 0/50, step: 492/2141.0, 11.55s/step, loss: 799.75531, cls loss: 1592.01294, reg loss: 7.49667\n",
      "Epoch: 0/50, step: 493/2141.0, 11.55s/step, loss: 798.16302, cls loss: 1588.84351, reg loss: 7.48157\n",
      "Epoch: 0/50, step: 494/2141.0, 11.55s/step, loss: 796.58563, cls loss: 1585.70325, reg loss: 7.46687\n",
      "Epoch: 0/50, step: 495/2141.0, 11.55s/step, loss: 795.01190, cls loss: 1582.57043, reg loss: 7.45226\n",
      "Epoch: 0/50, step: 496/2141.0, 11.56s/step, loss: 793.45392, cls loss: 1579.46814, reg loss: 7.43853\n",
      "Epoch: 0/50, step: 497/2141.0, 11.57s/step, loss: 791.90375, cls loss: 1576.37366, reg loss: 7.43278\n",
      "Epoch: 0/50, step: 498/2141.0, 11.56s/step, loss: 790.35449, cls loss: 1573.28040, reg loss: 7.42749\n",
      "Epoch: 0/50, step: 499/2141.0, 11.57s/step, loss: 788.80634, cls loss: 1570.19812, reg loss: 7.41334\n",
      "Epoch: 0/50, step: 500/2141.0, 11.57s/step, loss: 787.26245, cls loss: 1567.12512, reg loss: 7.39870\n",
      "Epoch: 0/50, step: 501/2141.0, 11.57s/step, loss: 785.72473, cls loss: 1564.06384, reg loss: 7.38436\n",
      "Epoch: 0/50, step: 502/2141.0, 11.57s/step, loss: 784.20270, cls loss: 1561.02722, reg loss: 7.37705\n",
      "Epoch: 0/50, step: 503/2141.0, 11.57s/step, loss: 782.67456, cls loss: 1557.98535, reg loss: 7.36258\n",
      "Epoch: 0/50, step: 504/2141.0, 11.57s/step, loss: 781.16541, cls loss: 1554.98132, reg loss: 7.34838\n",
      "Epoch: 0/50, step: 505/2141.0, 11.57s/step, loss: 779.64960, cls loss: 1551.96387, reg loss: 7.33427\n",
      "Epoch: 0/50, step: 506/2141.0, 11.57s/step, loss: 778.14600, cls loss: 1548.97095, reg loss: 7.32010\n",
      "Epoch: 0/50, step: 507/2141.0, 11.57s/step, loss: 776.64392, cls loss: 1545.98071, reg loss: 7.30612\n",
      "Epoch: 0/50, step: 508/2141.0, 11.57s/step, loss: 775.15125, cls loss: 1543.00940, reg loss: 7.29190\n",
      "Epoch: 0/50, step: 509/2141.0, 11.57s/step, loss: 773.66034, cls loss: 1540.04199, reg loss: 7.27769\n",
      "Epoch: 0/50, step: 510/2141.0, 11.57s/step, loss: 772.17285, cls loss: 1537.08093, reg loss: 7.26369\n",
      "Epoch: 0/50, step: 511/2141.0, 11.57s/step, loss: 770.70367, cls loss: 1534.15576, reg loss: 7.25061\n",
      "Epoch: 0/50, step: 512/2141.0, 11.57s/step, loss: 769.23621, cls loss: 1531.23376, reg loss: 7.23773\n",
      "Epoch: 0/50, step: 513/2141.0, 11.58s/step, loss: 767.76660, cls loss: 1528.30835, reg loss: 7.22398\n",
      "Epoch: 0/50, step: 514/2141.0, 11.57s/step, loss: 766.30884, cls loss: 1525.40588, reg loss: 7.21097\n",
      "Epoch: 0/50, step: 515/2141.0, 11.58s/step, loss: 764.85901, cls loss: 1522.51978, reg loss: 7.19741\n",
      "Epoch: 0/50, step: 516/2141.0, 11.58s/step, loss: 763.41034, cls loss: 1519.63623, reg loss: 7.18355\n",
      "Epoch: 0/50, step: 517/2141.0, 11.58s/step, loss: 761.96143, cls loss: 1516.75232, reg loss: 7.16968\n",
      "Epoch: 0/50, step: 518/2141.0, 11.59s/step, loss: 760.52606, cls loss: 1513.89502, reg loss: 7.15626\n",
      "Epoch: 0/50, step: 519/2141.0, 11.59s/step, loss: 759.09467, cls loss: 1511.04431, reg loss: 7.14400\n",
      "Epoch: 0/50, step: 520/2141.0, 11.59s/step, loss: 757.66357, cls loss: 1508.19592, reg loss: 7.13034\n",
      "Epoch: 0/50, step: 521/2141.0, 11.59s/step, loss: 756.23822, cls loss: 1505.35852, reg loss: 7.11699\n",
      "Epoch: 0/50, step: 522/2141.0, 11.59s/step, loss: 754.81628, cls loss: 1502.52808, reg loss: 7.10345\n",
      "Epoch: 0/50, step: 523/2141.0, 11.59s/step, loss: 753.40417, cls loss: 1499.71667, reg loss: 7.09064\n",
      "Epoch: 0/50, step: 524/2141.0, 11.59s/step, loss: 751.99463, cls loss: 1496.91101, reg loss: 7.07723\n",
      "Epoch: 0/50, step: 525/2141.0, 11.59s/step, loss: 750.58972, cls loss: 1494.11462, reg loss: 7.06383\n",
      "Epoch: 0/50, step: 526/2141.0, 11.59s/step, loss: 749.18805, cls loss: 1491.32471, reg loss: 7.05043\n",
      "Epoch: 0/50, step: 527/2141.0, 11.59s/step, loss: 747.80780, cls loss: 1488.57361, reg loss: 7.04105\n",
      "Epoch: 0/50, step: 528/2141.0, 11.59s/step, loss: 746.41962, cls loss: 1485.81042, reg loss: 7.02785\n",
      "Epoch: 0/50, step: 529/2141.0, 11.59s/step, loss: 745.04626, cls loss: 1483.07605, reg loss: 7.01551\n",
      "Epoch: 0/50, step: 530/2141.0, 11.59s/step, loss: 743.66870, cls loss: 1480.33398, reg loss: 7.00239\n",
      "Epoch: 0/50, step: 531/2141.0, 11.59s/step, loss: 742.30280, cls loss: 1477.61487, reg loss: 6.98965\n",
      "Epoch: 0/50, step: 532/2141.0, 11.59s/step, loss: 740.95087, cls loss: 1474.91113, reg loss: 6.98949\n",
      "Epoch: 0/50, step: 533/2141.0, 11.60s/step, loss: 739.60162, cls loss: 1472.22510, reg loss: 6.97715\n",
      "Epoch: 0/50, step: 534/2141.0, 11.60s/step, loss: 738.24615, cls loss: 1469.52686, reg loss: 6.96424\n",
      "Epoch: 0/50, step: 535/2141.0, 11.60s/step, loss: 736.89240, cls loss: 1466.83215, reg loss: 6.95136\n",
      "Epoch: 0/50, step: 536/2141.0, 11.61s/step, loss: 735.54407, cls loss: 1464.14844, reg loss: 6.93853\n",
      "Epoch: 0/50, step: 537/2141.0, 11.61s/step, loss: 734.20013, cls loss: 1461.47327, reg loss: 6.92575\n",
      "Epoch: 0/50, step: 538/2141.0, 11.61s/step, loss: 732.86389, cls loss: 1458.81335, reg loss: 6.91326\n",
      "Epoch: 0/50, step: 539/2141.0, 11.61s/step, loss: 731.53119, cls loss: 1456.16028, reg loss: 6.90084\n",
      "Epoch: 0/50, step: 540/2141.0, 11.61s/step, loss: 730.20312, cls loss: 1453.51660, reg loss: 6.88839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 541/2141.0, 11.62s/step, loss: 728.89294, cls loss: 1450.89172, reg loss: 6.89292\n",
      "Epoch: 0/50, step: 542/2141.0, 11.62s/step, loss: 727.57660, cls loss: 1448.27148, reg loss: 6.88048\n",
      "Epoch: 0/50, step: 543/2141.0, 11.62s/step, loss: 726.28589, cls loss: 1445.67871, reg loss: 6.89181\n",
      "Epoch: 0/50, step: 544/2141.0, 11.62s/step, loss: 724.98364, cls loss: 1443.08667, reg loss: 6.87938\n",
      "Epoch: 0/50, step: 545/2141.0, 11.63s/step, loss: 723.68207, cls loss: 1440.49585, reg loss: 6.86699\n",
      "Epoch: 0/50, step: 546/2141.0, 11.63s/step, loss: 722.38489, cls loss: 1437.91370, reg loss: 6.85475\n",
      "Epoch: 0/50, step: 547/2141.0, 11.63s/step, loss: 721.08899, cls loss: 1435.33447, reg loss: 6.84226\n",
      "Epoch: 0/50, step: 548/2141.0, 11.63s/step, loss: 719.79852, cls loss: 1432.76575, reg loss: 6.83003\n",
      "Epoch: 0/50, step: 549/2141.0, 11.63s/step, loss: 718.51416, cls loss: 1430.20935, reg loss: 6.81769\n",
      "Epoch: 0/50, step: 550/2141.0, 11.63s/step, loss: 717.23547, cls loss: 1427.66370, reg loss: 6.80596\n",
      "Epoch: 0/50, step: 551/2141.0, 11.63s/step, loss: 715.96790, cls loss: 1425.14001, reg loss: 6.79432\n",
      "Epoch: 0/50, step: 552/2141.0, 11.64s/step, loss: 714.71021, cls loss: 1422.63538, reg loss: 6.78369\n",
      "Epoch: 0/50, step: 553/2141.0, 11.64s/step, loss: 713.44177, cls loss: 1420.11072, reg loss: 6.77159\n",
      "Epoch: 0/50, step: 554/2141.0, 11.64s/step, loss: 712.17883, cls loss: 1417.59692, reg loss: 6.75943\n",
      "Epoch: 0/50, step: 555/2141.0, 11.64s/step, loss: 710.92615, cls loss: 1415.10303, reg loss: 6.74803\n",
      "Epoch: 0/50, step: 556/2141.0, 11.64s/step, loss: 709.67279, cls loss: 1412.60815, reg loss: 6.73609\n",
      "Epoch: 0/50, step: 557/2141.0, 11.64s/step, loss: 708.42151, cls loss: 1410.11755, reg loss: 6.72406\n",
      "Epoch: 0/50, step: 558/2141.0, 11.64s/step, loss: 707.18030, cls loss: 1407.64343, reg loss: 6.71569\n",
      "Epoch: 0/50, step: 559/2141.0, 11.64s/step, loss: 705.94592, cls loss: 1405.18628, reg loss: 6.70423\n",
      "Epoch: 0/50, step: 560/2141.0, 11.64s/step, loss: 704.71942, cls loss: 1402.74438, reg loss: 6.69304\n",
      "Epoch: 0/50, step: 561/2141.0, 11.64s/step, loss: 703.49133, cls loss: 1400.29858, reg loss: 6.68277\n",
      "Epoch: 0/50, step: 562/2141.0, 11.64s/step, loss: 702.27423, cls loss: 1397.86707, reg loss: 6.68029\n",
      "Epoch: 0/50, step: 563/2141.0, 11.65s/step, loss: 701.05231, cls loss: 1395.43469, reg loss: 6.66866\n",
      "Epoch: 0/50, step: 564/2141.0, 11.65s/step, loss: 699.85522, cls loss: 1393.04907, reg loss: 6.66023\n",
      "Epoch: 0/50, step: 565/2141.0, 11.65s/step, loss: 698.64667, cls loss: 1390.64062, reg loss: 6.65157\n",
      "Epoch: 0/50, step: 566/2141.0, 11.65s/step, loss: 697.43994, cls loss: 1388.23865, reg loss: 6.64011\n",
      "Epoch: 0/50, step: 567/2141.0, 11.65s/step, loss: 696.24158, cls loss: 1385.84961, reg loss: 6.63254\n",
      "Epoch: 0/50, step: 568/2141.0, 11.65s/step, loss: 695.04645, cls loss: 1383.46863, reg loss: 6.62332\n",
      "Epoch: 0/50, step: 569/2141.0, 11.65s/step, loss: 693.85132, cls loss: 1381.08984, reg loss: 6.61185\n",
      "Epoch: 0/50, step: 570/2141.0, 11.66s/step, loss: 692.65741, cls loss: 1378.71338, reg loss: 6.60049\n",
      "Epoch: 0/50, step: 571/2141.0, 11.66s/step, loss: 691.47089, cls loss: 1376.35034, reg loss: 6.59050\n",
      "Epoch: 0/50, step: 572/2141.0, 11.66s/step, loss: 690.29352, cls loss: 1374.00647, reg loss: 6.57967\n",
      "Epoch: 0/50, step: 573/2141.0, 11.66s/step, loss: 689.12280, cls loss: 1371.67493, reg loss: 6.56976\n",
      "Epoch: 0/50, step: 574/2141.0, 11.66s/step, loss: 687.95349, cls loss: 1369.34644, reg loss: 6.55953\n",
      "Epoch: 0/50, step: 575/2141.0, 11.66s/step, loss: 686.78278, cls loss: 1367.01611, reg loss: 6.54833\n",
      "Epoch: 0/50, step: 576/2141.0, 11.66s/step, loss: 685.61469, cls loss: 1364.69128, reg loss: 6.53707\n",
      "Epoch: 0/50, step: 577/2141.0, 11.66s/step, loss: 684.45343, cls loss: 1362.37976, reg loss: 6.52609\n",
      "Epoch: 0/50, step: 578/2141.0, 11.66s/step, loss: 683.30750, cls loss: 1360.09656, reg loss: 6.51732\n",
      "Epoch: 0/50, step: 579/2141.0, 11.66s/step, loss: 682.14911, cls loss: 1357.79077, reg loss: 6.50624\n",
      "Epoch: 0/50, step: 580/2141.0, 11.66s/step, loss: 680.99609, cls loss: 1355.49524, reg loss: 6.49565\n",
      "Epoch: 0/50, step: 581/2141.0, 11.66s/step, loss: 679.85083, cls loss: 1353.21497, reg loss: 6.48547\n",
      "Epoch: 0/50, step: 582/2141.0, 11.65s/step, loss: 678.71411, cls loss: 1350.95190, reg loss: 6.47518\n",
      "Epoch: 0/50, step: 583/2141.0, 11.66s/step, loss: 677.57697, cls loss: 1348.68799, reg loss: 6.46460\n",
      "Epoch: 0/50, step: 584/2141.0, 11.65s/step, loss: 676.43713, cls loss: 1346.41943, reg loss: 6.45359\n",
      "Epoch: 0/50, step: 585/2141.0, 11.66s/step, loss: 675.31183, cls loss: 1344.17957, reg loss: 6.44280\n",
      "Epoch: 0/50, step: 586/2141.0, 11.66s/step, loss: 674.18433, cls loss: 1341.93518, reg loss: 6.43223\n",
      "Epoch: 0/50, step: 587/2141.0, 11.66s/step, loss: 673.05872, cls loss: 1339.69458, reg loss: 6.42156\n",
      "Epoch: 0/50, step: 588/2141.0, 11.66s/step, loss: 671.94604, cls loss: 1337.47949, reg loss: 6.41124\n",
      "Epoch: 0/50, step: 589/2141.0, 11.66s/step, loss: 670.82916, cls loss: 1335.25635, reg loss: 6.40075\n",
      "Epoch: 0/50, step: 590/2141.0, 11.66s/step, loss: 669.71570, cls loss: 1333.03979, reg loss: 6.39029\n",
      "Epoch: 0/50, step: 591/2141.0, 11.66s/step, loss: 668.61798, cls loss: 1330.84351, reg loss: 6.39118\n",
      "Epoch: 0/50, step: 592/2141.0, 11.66s/step, loss: 667.51971, cls loss: 1328.65662, reg loss: 6.38155\n",
      "Epoch: 0/50, step: 593/2141.0, 11.66s/step, loss: 666.42627, cls loss: 1326.47192, reg loss: 6.37940\n",
      "Epoch: 0/50, step: 594/2141.0, 11.67s/step, loss: 665.32550, cls loss: 1324.28101, reg loss: 6.36886\n",
      "Epoch: 0/50, step: 595/2141.0, 11.68s/step, loss: 664.23822, cls loss: 1322.11597, reg loss: 6.35931\n",
      "Epoch: 0/50, step: 596/2141.0, 11.68s/step, loss: 663.14734, cls loss: 1319.94446, reg loss: 6.34898\n",
      "Epoch: 0/50, step: 597/2141.0, 11.68s/step, loss: 662.05994, cls loss: 1317.78015, reg loss: 6.33845\n",
      "Epoch: 0/50, step: 598/2141.0, 11.68s/step, loss: 660.97833, cls loss: 1315.62756, reg loss: 6.32800\n",
      "Epoch: 0/50, step: 599/2141.0, 11.68s/step, loss: 659.89764, cls loss: 1313.47644, reg loss: 6.31764\n",
      "Epoch: 0/50, step: 600/2141.0, 11.69s/step, loss: 658.82208, cls loss: 1311.33435, reg loss: 6.30862\n",
      "Epoch: 0/50, step: 601/2141.0, 11.69s/step, loss: 657.74847, cls loss: 1309.19751, reg loss: 6.29822\n",
      "Epoch: 0/50, step: 602/2141.0, 11.69s/step, loss: 656.68097, cls loss: 1307.07251, reg loss: 6.28824\n",
      "Epoch: 0/50, step: 603/2141.0, 11.69s/step, loss: 655.62152, cls loss: 1304.96204, reg loss: 6.27971\n",
      "Epoch: 0/50, step: 604/2141.0, 11.70s/step, loss: 654.56012, cls loss: 1302.84924, reg loss: 6.26961\n",
      "Epoch: 0/50, step: 605/2141.0, 11.70s/step, loss: 653.50360, cls loss: 1300.74597, reg loss: 6.25983\n",
      "Epoch: 0/50, step: 606/2141.0, 11.70s/step, loss: 652.44769, cls loss: 1298.64441, reg loss: 6.24969\n",
      "Epoch: 0/50, step: 607/2141.0, 11.70s/step, loss: 651.39532, cls loss: 1296.54956, reg loss: 6.23985\n",
      "Epoch: 0/50, step: 608/2141.0, 11.69s/step, loss: 650.34473, cls loss: 1294.45825, reg loss: 6.22993\n",
      "Epoch: 0/50, step: 609/2141.0, 11.69s/step, loss: 649.30133, cls loss: 1292.38086, reg loss: 6.22047\n",
      "Epoch: 0/50, step: 610/2141.0, 11.69s/step, loss: 648.25909, cls loss: 1290.30627, reg loss: 6.21055\n",
      "Epoch: 0/50, step: 611/2141.0, 11.70s/step, loss: 647.21924, cls loss: 1288.23608, reg loss: 6.20095\n",
      "Epoch: 0/50, step: 612/2141.0, 11.71s/step, loss: 646.18506, cls loss: 1286.17688, reg loss: 6.19176\n",
      "Epoch: 0/50, step: 613/2141.0, 11.70s/step, loss: 645.15192, cls loss: 1284.12073, reg loss: 6.18170\n",
      "Epoch: 0/50, step: 614/2141.0, 11.71s/step, loss: 644.13031, cls loss: 1282.08362, reg loss: 6.17558\n",
      "Epoch: 0/50, step: 615/2141.0, 11.70s/step, loss: 643.10443, cls loss: 1280.04175, reg loss: 6.16572\n",
      "Epoch: 0/50, step: 616/2141.0, 11.70s/step, loss: 642.08136, cls loss: 1278.00525, reg loss: 6.15607\n",
      "Epoch: 0/50, step: 617/2141.0, 11.71s/step, loss: 641.06116, cls loss: 1275.97461, reg loss: 6.14626\n",
      "Epoch: 0/50, step: 618/2141.0, 11.71s/step, loss: 640.05042, cls loss: 1273.95972, reg loss: 6.13973\n",
      "Epoch: 0/50, step: 619/2141.0, 11.71s/step, loss: 639.04108, cls loss: 1271.94995, reg loss: 6.13082\n",
      "Epoch: 0/50, step: 620/2141.0, 11.71s/step, loss: 638.02930, cls loss: 1269.93604, reg loss: 6.12116\n",
      "Epoch: 0/50, step: 621/2141.0, 11.71s/step, loss: 637.02142, cls loss: 1267.92957, reg loss: 6.11187\n",
      "Epoch: 0/50, step: 622/2141.0, 11.72s/step, loss: 636.01947, cls loss: 1265.93530, reg loss: 6.10225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 623/2141.0, 11.72s/step, loss: 635.01862, cls loss: 1263.94336, reg loss: 6.09262\n",
      "Epoch: 0/50, step: 624/2141.0, 11.72s/step, loss: 634.01886, cls loss: 1261.95349, reg loss: 6.08290\n",
      "Epoch: 0/50, step: 625/2141.0, 11.72s/step, loss: 633.02179, cls loss: 1259.96899, reg loss: 6.07326\n",
      "Epoch: 0/50, step: 626/2141.0, 11.72s/step, loss: 632.02948, cls loss: 1257.99402, reg loss: 6.06370\n",
      "Epoch: 0/50, step: 627/2141.0, 11.72s/step, loss: 631.05646, cls loss: 1256.05627, reg loss: 6.05528\n",
      "Epoch: 0/50, step: 628/2141.0, 11.72s/step, loss: 630.07385, cls loss: 1254.10022, reg loss: 6.04610\n",
      "Epoch: 0/50, step: 629/2141.0, 11.72s/step, loss: 629.10248, cls loss: 1252.16577, reg loss: 6.03785\n",
      "Epoch: 0/50, step: 630/2141.0, 11.72s/step, loss: 628.12476, cls loss: 1250.21973, reg loss: 6.02844\n",
      "Epoch: 0/50, step: 631/2141.0, 11.72s/step, loss: 627.15198, cls loss: 1248.28357, reg loss: 6.01913\n",
      "Epoch: 0/50, step: 632/2141.0, 11.72s/step, loss: 626.17999, cls loss: 1246.34863, reg loss: 6.01001\n",
      "Epoch: 0/50, step: 633/2141.0, 11.72s/step, loss: 625.21497, cls loss: 1244.42554, reg loss: 6.00301\n",
      "Epoch: 0/50, step: 634/2141.0, 11.72s/step, loss: 624.26172, cls loss: 1242.52002, reg loss: 6.00213\n",
      "Epoch: 0/50, step: 635/2141.0, 11.72s/step, loss: 623.29889, cls loss: 1240.60364, reg loss: 5.99294\n",
      "Epoch: 0/50, step: 636/2141.0, 11.72s/step, loss: 622.33887, cls loss: 1238.69287, reg loss: 5.98357\n",
      "Epoch: 0/50, step: 637/2141.0, 11.72s/step, loss: 621.38202, cls loss: 1236.78784, reg loss: 5.97483\n",
      "Epoch: 0/50, step: 638/2141.0, 11.72s/step, loss: 620.43018, cls loss: 1234.89331, reg loss: 5.96571\n",
      "Epoch: 0/50, step: 639/2141.0, 11.72s/step, loss: 619.47748, cls loss: 1232.99707, reg loss: 5.95659\n",
      "Epoch: 0/50, step: 640/2141.0, 11.72s/step, loss: 618.52905, cls loss: 1231.10889, reg loss: 5.94784\n",
      "Epoch: 0/50, step: 641/2141.0, 11.72s/step, loss: 617.58398, cls loss: 1229.22778, reg loss: 5.93887\n",
      "Epoch: 0/50, step: 642/2141.0, 11.71s/step, loss: 616.63983, cls loss: 1227.34851, reg loss: 5.92979\n",
      "Epoch: 0/50, step: 643/2141.0, 11.71s/step, loss: 615.70312, cls loss: 1225.48267, reg loss: 5.92229\n",
      "Epoch: 0/50, step: 644/2141.0, 11.71s/step, loss: 614.76331, cls loss: 1223.61230, reg loss: 5.91313\n",
      "Epoch: 0/50, step: 645/2141.0, 11.71s/step, loss: 613.82770, cls loss: 1221.75012, reg loss: 5.90406\n",
      "Epoch: 0/50, step: 646/2141.0, 11.71s/step, loss: 612.89606, cls loss: 1219.89526, reg loss: 5.89563\n",
      "Epoch: 0/50, step: 647/2141.0, 11.71s/step, loss: 611.96558, cls loss: 1218.04333, reg loss: 5.88660\n",
      "Epoch: 0/50, step: 648/2141.0, 11.71s/step, loss: 611.03888, cls loss: 1216.19885, reg loss: 5.87756\n",
      "Epoch: 0/50, step: 649/2141.0, 11.72s/step, loss: 610.11780, cls loss: 1214.36560, reg loss: 5.86873\n",
      "Epoch: 0/50, step: 650/2141.0, 11.72s/step, loss: 609.19574, cls loss: 1212.53003, reg loss: 5.86019\n",
      "Epoch: 0/50, step: 651/2141.0, 11.72s/step, loss: 608.27557, cls loss: 1210.69849, reg loss: 5.85123\n",
      "Epoch: 0/50, step: 652/2141.0, 11.72s/step, loss: 607.36298, cls loss: 1208.88232, reg loss: 5.84233\n",
      "Epoch: 0/50, step: 653/2141.0, 11.72s/step, loss: 606.44794, cls loss: 1207.06116, reg loss: 5.83345\n",
      "Epoch: 0/50, step: 654/2141.0, 11.72s/step, loss: 605.54169, cls loss: 1205.25671, reg loss: 5.82536\n",
      "Epoch: 0/50, step: 655/2141.0, 11.72s/step, loss: 604.63446, cls loss: 1203.45117, reg loss: 5.81658\n",
      "Epoch: 0/50, step: 656/2141.0, 11.72s/step, loss: 603.73743, cls loss: 1201.66528, reg loss: 5.80839\n",
      "Epoch: 0/50, step: 657/2141.0, 11.71s/step, loss: 602.84235, cls loss: 1199.88342, reg loss: 5.80005\n",
      "Epoch: 0/50, step: 658/2141.0, 11.71s/step, loss: 601.94757, cls loss: 1198.10242, reg loss: 5.79156\n",
      "Epoch: 0/50, step: 659/2141.0, 11.71s/step, loss: 601.05170, cls loss: 1196.31934, reg loss: 5.78291\n",
      "Epoch: 0/50, step: 660/2141.0, 11.71s/step, loss: 600.15845, cls loss: 1194.54114, reg loss: 5.77467\n",
      "Epoch: 0/50, step: 661/2141.0, 11.71s/step, loss: 599.26721, cls loss: 1192.76697, reg loss: 5.76619\n",
      "Epoch: 0/50, step: 662/2141.0, 11.71s/step, loss: 598.38293, cls loss: 1191.00684, reg loss: 5.75778\n",
      "Epoch: 0/50, step: 663/2141.0, 11.71s/step, loss: 597.49689, cls loss: 1189.24341, reg loss: 5.74915\n",
      "Epoch: 0/50, step: 664/2141.0, 11.71s/step, loss: 596.61798, cls loss: 1187.49402, reg loss: 5.74072\n",
      "Epoch: 0/50, step: 665/2141.0, 11.71s/step, loss: 595.73798, cls loss: 1185.74243, reg loss: 5.73223\n",
      "Epoch: 0/50, step: 666/2141.0, 11.70s/step, loss: 594.86285, cls loss: 1184.00061, reg loss: 5.72393\n",
      "Epoch: 0/50, step: 667/2141.0, 11.70s/step, loss: 593.99249, cls loss: 1182.26709, reg loss: 5.71666\n",
      "Epoch: 0/50, step: 668/2141.0, 11.70s/step, loss: 593.12109, cls loss: 1180.53259, reg loss: 5.70830\n",
      "Epoch: 0/50, step: 669/2141.0, 11.70s/step, loss: 592.25146, cls loss: 1178.80164, reg loss: 5.70004\n",
      "Epoch: 0/50, step: 670/2141.0, 11.70s/step, loss: 591.38928, cls loss: 1177.08545, reg loss: 5.69195\n",
      "Epoch: 0/50, step: 671/2141.0, 11.70s/step, loss: 590.52588, cls loss: 1175.36633, reg loss: 5.68418\n",
      "Epoch: 0/50, step: 672/2141.0, 11.70s/step, loss: 589.67426, cls loss: 1173.66870, reg loss: 5.67864\n",
      "Epoch: 0/50, step: 673/2141.0, 11.70s/step, loss: 588.81665, cls loss: 1171.96118, reg loss: 5.67075\n",
      "Epoch: 0/50, step: 674/2141.0, 11.70s/step, loss: 587.96594, cls loss: 1170.26782, reg loss: 5.66274\n",
      "Epoch: 0/50, step: 675/2141.0, 11.69s/step, loss: 587.11102, cls loss: 1168.56641, reg loss: 5.65441\n",
      "Epoch: 0/50, step: 676/2141.0, 11.69s/step, loss: 586.25940, cls loss: 1166.87146, reg loss: 5.64619\n",
      "Epoch: 0/50, step: 677/2141.0, 11.69s/step, loss: 585.41547, cls loss: 1165.19141, reg loss: 5.63829\n",
      "Epoch: 0/50, step: 678/2141.0, 11.69s/step, loss: 584.57507, cls loss: 1163.51855, reg loss: 5.63034\n",
      "Epoch: 0/50, step: 679/2141.0, 11.69s/step, loss: 583.73370, cls loss: 1161.84363, reg loss: 5.62260\n",
      "Epoch: 0/50, step: 680/2141.0, 11.69s/step, loss: 582.89264, cls loss: 1160.16956, reg loss: 5.61450\n",
      "Epoch: 0/50, step: 681/2141.0, 11.68s/step, loss: 582.05304, cls loss: 1158.49841, reg loss: 5.60637\n",
      "Epoch: 0/50, step: 682/2141.0, 11.68s/step, loss: 581.22028, cls loss: 1156.84082, reg loss: 5.59855\n",
      "Epoch: 0/50, step: 683/2141.0, 11.68s/step, loss: 580.38342, cls loss: 1155.17529, reg loss: 5.59036\n",
      "Epoch: 0/50, step: 684/2141.0, 11.68s/step, loss: 579.55255, cls loss: 1153.52136, reg loss: 5.58258\n",
      "Epoch: 0/50, step: 685/2141.0, 11.68s/step, loss: 578.72534, cls loss: 1151.87488, reg loss: 5.57474\n",
      "Epoch: 0/50, step: 686/2141.0, 11.68s/step, loss: 577.89862, cls loss: 1150.22937, reg loss: 5.56674\n",
      "Epoch: 0/50, step: 687/2141.0, 11.68s/step, loss: 577.07526, cls loss: 1148.59045, reg loss: 5.55892\n",
      "Epoch: 0/50, step: 688/2141.0, 11.67s/step, loss: 576.25256, cls loss: 1146.95300, reg loss: 5.55104\n",
      "Epoch: 0/50, step: 689/2141.0, 11.67s/step, loss: 575.43610, cls loss: 1145.32739, reg loss: 5.54360\n",
      "Epoch: 0/50, step: 690/2141.0, 11.67s/step, loss: 574.61731, cls loss: 1143.69751, reg loss: 5.53601\n",
      "Epoch: 0/50, step: 691/2141.0, 11.67s/step, loss: 573.80011, cls loss: 1142.07104, reg loss: 5.52809\n",
      "Epoch: 0/50, step: 692/2141.0, 11.67s/step, loss: 572.99158, cls loss: 1140.46155, reg loss: 5.52044\n",
      "Epoch: 0/50, step: 693/2141.0, 11.67s/step, loss: 572.18726, cls loss: 1138.86023, reg loss: 5.51307\n",
      "Epoch: 0/50, step: 694/2141.0, 11.67s/step, loss: 571.37701, cls loss: 1137.24756, reg loss: 5.50520\n",
      "Epoch: 0/50, step: 695/2141.0, 11.67s/step, loss: 570.57147, cls loss: 1135.64429, reg loss: 5.49740\n",
      "Epoch: 0/50, step: 696/2141.0, 11.67s/step, loss: 569.77020, cls loss: 1134.04932, reg loss: 5.48990\n",
      "Epoch: 0/50, step: 697/2141.0, 11.66s/step, loss: 568.96753, cls loss: 1132.45166, reg loss: 5.48216\n",
      "Epoch: 0/50, step: 698/2141.0, 11.66s/step, loss: 568.16754, cls loss: 1130.85925, reg loss: 5.47459\n",
      "Epoch: 0/50, step: 699/2141.0, 11.66s/step, loss: 567.37054, cls loss: 1129.27246, reg loss: 5.46726\n",
      "Epoch: 0/50, step: 700/2141.0, 11.66s/step, loss: 566.57318, cls loss: 1127.68555, reg loss: 5.45946\n",
      "Epoch: 0/50, step: 701/2141.0, 11.66s/step, loss: 565.78149, cls loss: 1126.10974, reg loss: 5.45197\n",
      "Epoch: 0/50, step: 702/2141.0, 11.66s/step, loss: 564.98987, cls loss: 1124.53394, reg loss: 5.44437\n",
      "Epoch: 0/50, step: 703/2141.0, 11.66s/step, loss: 564.20453, cls loss: 1122.97046, reg loss: 5.43726\n",
      "Epoch: 0/50, step: 704/2141.0, 11.66s/step, loss: 563.42084, cls loss: 1121.41016, reg loss: 5.43006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, step: 705/2141.0, 11.66s/step, loss: 562.63715, cls loss: 1119.85034, reg loss: 5.42255\n",
      "Epoch: 0/50, step: 706/2141.0, 11.66s/step, loss: 561.85901, cls loss: 1118.30103, reg loss: 5.41554\n",
      "Epoch: 0/50, step: 707/2141.0, 11.66s/step, loss: 561.07806, cls loss: 1116.74670, reg loss: 5.40801\n",
      "Epoch: 0/50, step: 708/2141.0, 11.66s/step, loss: 560.29865, cls loss: 1115.19531, reg loss: 5.40063\n",
      "Epoch: 0/50, step: 709/2141.0, 11.66s/step, loss: 559.52814, cls loss: 1113.66150, reg loss: 5.39331\n",
      "Epoch: 0/50, step: 710/2141.0, 11.66s/step, loss: 558.75464, cls loss: 1112.12207, reg loss: 5.38582\n",
      "Epoch: 0/50, step: 711/2141.0, 11.66s/step, loss: 557.98236, cls loss: 1110.58484, reg loss: 5.37840\n",
      "Epoch: 0/50, step: 712/2141.0, 11.65s/step, loss: 557.21259, cls loss: 1109.05273, reg loss: 5.37101\n",
      "Epoch: 0/50, step: 713/2141.0, 11.65s/step, loss: 556.44733, cls loss: 1107.52942, reg loss: 5.36383\n",
      "Epoch: 0/50, step: 714/2141.0, 11.65s/step, loss: 555.68146, cls loss: 1106.00500, reg loss: 5.35657\n",
      "Epoch: 0/50, step: 715/2141.0, 11.65s/step, loss: 554.92194, cls loss: 1104.49304, reg loss: 5.34948\n",
      "Epoch: 0/50, step: 716/2141.0, 11.65s/step, loss: 554.16205, cls loss: 1102.98022, reg loss: 5.34250\n",
      "Epoch: 0/50, step: 717/2141.0, 11.65s/step, loss: 553.40717, cls loss: 1101.47742, reg loss: 5.33543\n",
      "Epoch: 0/50, step: 718/2141.0, 11.65s/step, loss: 552.65387, cls loss: 1099.97803, reg loss: 5.32820\n",
      "Epoch: 0/50, step: 719/2141.0, 11.64s/step, loss: 551.89789, cls loss: 1098.47339, reg loss: 5.32090\n",
      "Epoch: 0/50, step: 720/2141.0, 11.64s/step, loss: 551.14752, cls loss: 1096.97974, reg loss: 5.31388\n",
      "Epoch: 0/50, step: 721/2141.0, 11.64s/step, loss: 550.40051, cls loss: 1095.49268, reg loss: 5.30690\n",
      "Epoch: 0/50, step: 722/2141.0, 11.64s/step, loss: 549.65424, cls loss: 1094.00720, reg loss: 5.29978\n",
      "Epoch: 0/50, step: 723/2141.0, 11.64s/step, loss: 548.91345, cls loss: 1092.53259, reg loss: 5.29286\n",
      "Epoch: 0/50, step: 724/2141.0, 11.64s/step, loss: 548.16980, cls loss: 1091.05237, reg loss: 5.28567\n",
      "Epoch: 0/50, step: 725/2141.0, 11.64s/step, loss: 547.43365, cls loss: 1089.58716, reg loss: 5.27863\n",
      "Epoch: 0/50, step: 726/2141.0, 11.64s/step, loss: 546.69727, cls loss: 1088.12134, reg loss: 5.27167\n",
      "Epoch: 0/50, step: 727/2141.0, 11.63s/step, loss: 545.96619, cls loss: 1086.66504, reg loss: 5.26583\n",
      "Epoch: 0/50, step: 728/2141.0, 11.64s/step, loss: 545.25134, cls loss: 1085.22888, reg loss: 5.27254\n",
      "Epoch: 0/50, step: 729/2141.0, 11.63s/step, loss: 544.51611, cls loss: 1083.76538, reg loss: 5.26538\n",
      "Epoch: 0/50, step: 730/2141.0, 11.64s/step, loss: 543.78558, cls loss: 1082.31140, reg loss: 5.25838\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from configuration import IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS, EPOCHS, NUM_CLASSES, BATCH_SIZE, save_model_dir, \\\n",
    "    load_weights_before_training, load_weights_from_epoch, save_frequency, test_images_during_training, \\\n",
    "    test_images_dir_list\n",
    "from core.ground_truth import ReadDataset, MakeGT\n",
    "from core.loss import SSDLoss\n",
    "from core.make_dataset import TFDataset\n",
    "from core.ssd import SSD, ssd_prediction\n",
    "from utils.visualize import visualize_training_results\n",
    "\n",
    "\n",
    "def print_model_summary(network):\n",
    "    network.build(input_shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "    network.summary()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GPU settings\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    dataset = TFDataset()\n",
    "    train_data, train_count = dataset.generate_datatset()\n",
    "\n",
    "    ssd = SSD()\n",
    "    print_model_summary(network=ssd)\n",
    "\n",
    "    if load_weights_before_training:\n",
    "        ssd.load_weights(filepath=save_model_dir+\"epoch-{}\".format(load_weights_from_epoch))\n",
    "        print(\"Successfully load weights!\")\n",
    "    else:\n",
    "        load_weights_from_epoch = -1\n",
    "\n",
    "    # loss\n",
    "    loss = SSDLoss()\n",
    "\n",
    "    # optimizer\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,\n",
    "                                                                 decay_steps=20000,\n",
    "                                                                 decay_rate=0.96)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # metrics\n",
    "    loss_metric = tf.metrics.Mean()\n",
    "    cls_loss_metric = tf.metrics.Mean()\n",
    "    reg_loss_metric = tf.metrics.Mean()\n",
    "\n",
    "    def train_step(batch_images, batch_labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = ssd(batch_images, training=True)\n",
    "            output = ssd_prediction(feature_maps=pred, num_classes=NUM_CLASSES)\n",
    "            gt = MakeGT(batch_labels, pred)\n",
    "            gt_boxes = gt.generate_gt_boxes()\n",
    "            loss_value, cls_loss, reg_loss = loss(y_true=gt_boxes, y_pred=output)\n",
    "        gradients = tape.gradient(loss_value, ssd.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(gradients, ssd.trainable_variables))\n",
    "        loss_metric.update_state(values=loss_value)\n",
    "        cls_loss_metric.update_state(values=cls_loss)\n",
    "        reg_loss_metric.update_state(values=reg_loss)\n",
    "\n",
    "\n",
    "    for epoch in range(load_weights_from_epoch + 1, EPOCHS):\n",
    "        start_time = time.time()\n",
    "        for step, batch_data in enumerate(train_data):\n",
    "            images, labels = ReadDataset().read(batch_data)\n",
    "            train_step(batch_images=images, batch_labels=labels)\n",
    "            time_per_step = (time.time() - start_time) / (step + 1)\n",
    "            print(\"Epoch: {}/{}, step: {}/{}, {:.2f}s/step, loss: {:.5f}, \"\n",
    "                  \"cls loss: {:.5f}, reg loss: {:.5f}\".format(epoch,\n",
    "                                                              EPOCHS,\n",
    "                                                              step,\n",
    "                                                              tf.math.ceil(train_count / BATCH_SIZE),\n",
    "                                                              time_per_step,\n",
    "                                                              loss_metric.result(),\n",
    "                                                              cls_loss_metric.result(),\n",
    "                                                              reg_loss_metric.result()))\n",
    "        loss_metric.reset_states()\n",
    "        cls_loss_metric.reset_states()\n",
    "        reg_loss_metric.reset_states()\n",
    "\n",
    "        if epoch % save_frequency == 0:\n",
    "            ssd.save_weights(filepath=save_model_dir+\"epoch-{}\".format(epoch), save_format=\"tf\")\n",
    "\n",
    "        if test_images_during_training:\n",
    "            visualize_training_results(pictures=test_images_dir_list, model=ssd, epoch=epoch)\n",
    "\n",
    "    ssd.save_weights(filepath=save_model_dir+\"saved_model\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computerVision]",
   "language": "python",
   "name": "conda-env-computerVision-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
